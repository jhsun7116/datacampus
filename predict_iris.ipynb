{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0727_03_predict_iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vec_cArRxn9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "47cef796-b82e-412a-aa83-f5421fc3121e"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnqdj9XRy35A",
        "colab_type": "text"
      },
      "source": [
        "데이터 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t68HXmYy4-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4bff35c6-7871-4320-be37-d14fc295b959"
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"iris.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\")\n",
        "dataset_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/iris.data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_1E_mk7zQI2",
        "colab_type": "text"
      },
      "source": [
        "데이터 확인하기 (외부에서 데이터를 받았을 경우 필수적인 부분)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcsLJSFlzRt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "30d63d9c-da89-4168-b369-4b5e82193255"
      },
      "source": [
        "column_names = ['sepal length in cm','sepal width in cm','petal length in cm','petal width in cm','class']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\",\", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length in cm</th>\n",
              "      <th>sepal width in cm</th>\n",
              "      <th>petal length in cm</th>\n",
              "      <th>petal width in cm</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length in cm  sepal width in cm  ...  petal width in cm           class\n",
              "145                 6.7                3.0  ...                2.3  Iris-virginica\n",
              "146                 6.3                2.5  ...                1.9  Iris-virginica\n",
              "147                 6.5                3.0  ...                2.0  Iris-virginica\n",
              "148                 6.2                3.4  ...                2.3  Iris-virginica\n",
              "149                 5.9                3.0  ...                1.8  Iris-virginica\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M_MsKlI4iod",
        "colab_type": "text"
      },
      "source": [
        "데이터셋 생성하기 - 입력(속성값 4개)와 출력(판정결과 1개) 변수로 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA_ryJ784jp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae17f6f3-740e-4527-9800-86cb7f20d4b5"
      },
      "source": [
        "X = dataset.iloc[:, 0:4]\n",
        "y = dataset.iloc[:, 4]\n",
        "\n",
        "print(set(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Iris-virginica', 'Iris-versicolor', 'Iris-setosa'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAWXJh8K5BoP",
        "colab_type": "text"
      },
      "source": [
        "레이블을 범주형 형태로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5xLch8R5FPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "99358e34-d378-4454-a13e-16030942b121"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "Y_encodered = encoder.transform(y)\n",
        "\n",
        "print(Y_encodered)\n",
        "\n",
        "Y = np_utils.to_categorical(Y_encodered)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ugR3t25RzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05f6f601-d639-4801-b1bc-e5dba28271e5"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ISZE1lv5dt8",
        "colab_type": "text"
      },
      "source": [
        "학습/데이터 8:2 비율로 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o7rLFsw5fDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4867c5c6-e355-4ea9-937d-b13105f5570e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(120, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz4EJhVQ5ukQ",
        "colab_type": "text"
      },
      "source": [
        "모델 구성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ975Auw51A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(16, input_shape=(4,), activation='relu'))\n",
        "model.add(Dense(3, activation='softmax')) # 다중분류니까 소프트맥스를 사용"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vodu2ua6qHk",
        "colab_type": "text"
      },
      "source": [
        "모델 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oiZwJqA6qzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Nomt886yMw",
        "colab_type": "text"
      },
      "source": [
        "모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQf1ll9v60v_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7861d63-3093-492f-fe0a-8c829c78ae0c"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=200, \n",
        "                    batch_size=10,\n",
        "                    validation_data = (X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/200\n",
            "120/120 [==============================] - 0s 629us/step - loss: 2.2339 - accuracy: 0.3583 - val_loss: 2.3727 - val_accuracy: 0.2333\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 1.9708 - accuracy: 0.3583 - val_loss: 2.0899 - val_accuracy: 0.2333\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 1.7710 - accuracy: 0.3667 - val_loss: 1.8549 - val_accuracy: 0.2333\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 1.5864 - accuracy: 0.4000 - val_loss: 1.6692 - val_accuracy: 0.2667\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 1.4337 - accuracy: 0.5083 - val_loss: 1.5092 - val_accuracy: 0.3333\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 1.2893 - accuracy: 0.5333 - val_loss: 1.3732 - val_accuracy: 0.3333\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 1.1731 - accuracy: 0.5333 - val_loss: 1.2384 - val_accuracy: 0.4000\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 1.0634 - accuracy: 0.5500 - val_loss: 1.1382 - val_accuracy: 0.4000\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.9850 - accuracy: 0.5500 - val_loss: 1.0584 - val_accuracy: 0.4000\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.9244 - accuracy: 0.5500 - val_loss: 1.0063 - val_accuracy: 0.3333\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 0s 159us/step - loss: 0.8759 - accuracy: 0.5333 - val_loss: 0.9628 - val_accuracy: 0.3333\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.8410 - accuracy: 0.5167 - val_loss: 0.9327 - val_accuracy: 0.3000\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.8108 - accuracy: 0.5000 - val_loss: 0.8948 - val_accuracy: 0.3000\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.7815 - accuracy: 0.4833 - val_loss: 0.8759 - val_accuracy: 0.2667\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.7566 - accuracy: 0.4917 - val_loss: 0.8527 - val_accuracy: 0.3333\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.7357 - accuracy: 0.6250 - val_loss: 0.8313 - val_accuracy: 0.6000\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.7169 - accuracy: 0.8000 - val_loss: 0.8074 - val_accuracy: 0.6333\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.6993 - accuracy: 0.8000 - val_loss: 0.7938 - val_accuracy: 0.6333\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.6811 - accuracy: 0.7833 - val_loss: 0.7795 - val_accuracy: 0.6333\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.6658 - accuracy: 0.7917 - val_loss: 0.7611 - val_accuracy: 0.6333\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.6514 - accuracy: 0.8167 - val_loss: 0.7445 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.6378 - accuracy: 0.8250 - val_loss: 0.7332 - val_accuracy: 0.6667\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.6244 - accuracy: 0.8333 - val_loss: 0.7151 - val_accuracy: 0.6667\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.6117 - accuracy: 0.8500 - val_loss: 0.7012 - val_accuracy: 0.6667\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.6005 - accuracy: 0.8583 - val_loss: 0.6844 - val_accuracy: 0.7333\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.5880 - accuracy: 0.8583 - val_loss: 0.6735 - val_accuracy: 0.7333\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 0s 155us/step - loss: 0.5760 - accuracy: 0.8583 - val_loss: 0.6670 - val_accuracy: 0.7000\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 0s 157us/step - loss: 0.5658 - accuracy: 0.8583 - val_loss: 0.6537 - val_accuracy: 0.7333\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.5550 - accuracy: 0.8583 - val_loss: 0.6377 - val_accuracy: 0.7667\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.5446 - accuracy: 0.8750 - val_loss: 0.6281 - val_accuracy: 0.7667\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.5340 - accuracy: 0.8750 - val_loss: 0.6199 - val_accuracy: 0.7667\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 0s 157us/step - loss: 0.5251 - accuracy: 0.8750 - val_loss: 0.6039 - val_accuracy: 0.8000\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.5154 - accuracy: 0.8833 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.5082 - accuracy: 0.8917 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.4986 - accuracy: 0.8833 - val_loss: 0.5870 - val_accuracy: 0.7667\n",
            "Epoch 36/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.4890 - accuracy: 0.8750 - val_loss: 0.5689 - val_accuracy: 0.8000\n",
            "Epoch 37/200\n",
            "120/120 [==============================] - 0s 176us/step - loss: 0.4805 - accuracy: 0.9000 - val_loss: 0.5514 - val_accuracy: 0.8333\n",
            "Epoch 38/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.4736 - accuracy: 0.9083 - val_loss: 0.5525 - val_accuracy: 0.8000\n",
            "Epoch 39/200\n",
            "120/120 [==============================] - 0s 155us/step - loss: 0.4652 - accuracy: 0.9000 - val_loss: 0.5399 - val_accuracy: 0.8333\n",
            "Epoch 40/200\n",
            "120/120 [==============================] - 0s 175us/step - loss: 0.4568 - accuracy: 0.9083 - val_loss: 0.5338 - val_accuracy: 0.8333\n",
            "Epoch 41/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.4502 - accuracy: 0.9083 - val_loss: 0.5209 - val_accuracy: 0.8333\n",
            "Epoch 42/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.4428 - accuracy: 0.9167 - val_loss: 0.5134 - val_accuracy: 0.8333\n",
            "Epoch 43/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.4353 - accuracy: 0.9083 - val_loss: 0.5144 - val_accuracy: 0.8333\n",
            "Epoch 44/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.4301 - accuracy: 0.9167 - val_loss: 0.4991 - val_accuracy: 0.8333\n",
            "Epoch 45/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.4222 - accuracy: 0.9167 - val_loss: 0.4958 - val_accuracy: 0.8333\n",
            "Epoch 46/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.4176 - accuracy: 0.9083 - val_loss: 0.4929 - val_accuracy: 0.8333\n",
            "Epoch 47/200\n",
            "120/120 [==============================] - 0s 122us/step - loss: 0.4096 - accuracy: 0.9083 - val_loss: 0.4760 - val_accuracy: 0.8333\n",
            "Epoch 48/200\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.4037 - accuracy: 0.9250 - val_loss: 0.4705 - val_accuracy: 0.8333\n",
            "Epoch 49/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.3988 - accuracy: 0.9500 - val_loss: 0.4624 - val_accuracy: 0.8333\n",
            "Epoch 50/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.3924 - accuracy: 0.9167 - val_loss: 0.4695 - val_accuracy: 0.8333\n",
            "Epoch 51/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.3866 - accuracy: 0.9167 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
            "Epoch 52/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.3811 - accuracy: 0.9417 - val_loss: 0.4454 - val_accuracy: 0.8667\n",
            "Epoch 53/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.3772 - accuracy: 0.9250 - val_loss: 0.4447 - val_accuracy: 0.8333\n",
            "Epoch 54/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.3712 - accuracy: 0.9500 - val_loss: 0.4350 - val_accuracy: 0.8667\n",
            "Epoch 55/200\n",
            "120/120 [==============================] - 0s 129us/step - loss: 0.3657 - accuracy: 0.9500 - val_loss: 0.4346 - val_accuracy: 0.8333\n",
            "Epoch 56/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.3612 - accuracy: 0.9333 - val_loss: 0.4303 - val_accuracy: 0.8333\n",
            "Epoch 57/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.3576 - accuracy: 0.9667 - val_loss: 0.4172 - val_accuracy: 0.9000\n",
            "Epoch 58/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.3522 - accuracy: 0.9333 - val_loss: 0.4247 - val_accuracy: 0.8333\n",
            "Epoch 59/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.3495 - accuracy: 0.9667 - val_loss: 0.4060 - val_accuracy: 0.9000\n",
            "Epoch 60/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.3436 - accuracy: 0.9417 - val_loss: 0.4160 - val_accuracy: 0.8333\n",
            "Epoch 61/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.3382 - accuracy: 0.9500 - val_loss: 0.4046 - val_accuracy: 0.8667\n",
            "Epoch 62/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.3343 - accuracy: 0.9667 - val_loss: 0.3966 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.3327 - accuracy: 0.9500 - val_loss: 0.4043 - val_accuracy: 0.8333\n",
            "Epoch 64/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.3262 - accuracy: 0.9583 - val_loss: 0.3870 - val_accuracy: 0.9000\n",
            "Epoch 65/200\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.3225 - accuracy: 0.9667 - val_loss: 0.3809 - val_accuracy: 0.9000\n",
            "Epoch 66/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.3204 - accuracy: 0.9500 - val_loss: 0.3917 - val_accuracy: 0.8667\n",
            "Epoch 67/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.3163 - accuracy: 0.9583 - val_loss: 0.3704 - val_accuracy: 0.9000\n",
            "Epoch 68/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.3106 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.9000\n",
            "Epoch 69/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.3068 - accuracy: 0.9667 - val_loss: 0.3736 - val_accuracy: 0.9000\n",
            "Epoch 70/200\n",
            "120/120 [==============================] - 0s 159us/step - loss: 0.3036 - accuracy: 0.9667 - val_loss: 0.3671 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.2997 - accuracy: 0.9667 - val_loss: 0.3660 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2970 - accuracy: 0.9667 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2936 - accuracy: 0.9750 - val_loss: 0.3564 - val_accuracy: 0.9000\n",
            "Epoch 74/200\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.2895 - accuracy: 0.9667 - val_loss: 0.3582 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.2867 - accuracy: 0.9667 - val_loss: 0.3533 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.2835 - accuracy: 0.9667 - val_loss: 0.3495 - val_accuracy: 0.9000\n",
            "Epoch 77/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.2812 - accuracy: 0.9750 - val_loss: 0.3409 - val_accuracy: 0.9000\n",
            "Epoch 78/200\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.2782 - accuracy: 0.9750 - val_loss: 0.3457 - val_accuracy: 0.9000\n",
            "Epoch 79/200\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.2747 - accuracy: 0.9667 - val_loss: 0.3392 - val_accuracy: 0.9000\n",
            "Epoch 80/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.2722 - accuracy: 0.9750 - val_loss: 0.3376 - val_accuracy: 0.9000\n",
            "Epoch 81/200\n",
            "120/120 [==============================] - 0s 192us/step - loss: 0.2684 - accuracy: 0.9833 - val_loss: 0.3302 - val_accuracy: 0.9000\n",
            "Epoch 82/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2660 - accuracy: 0.9833 - val_loss: 0.3259 - val_accuracy: 0.9000\n",
            "Epoch 83/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2632 - accuracy: 0.9833 - val_loss: 0.3311 - val_accuracy: 0.9000\n",
            "Epoch 84/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.2604 - accuracy: 0.9833 - val_loss: 0.3234 - val_accuracy: 0.9000\n",
            "Epoch 85/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.2579 - accuracy: 0.9833 - val_loss: 0.3174 - val_accuracy: 0.9000\n",
            "Epoch 86/200\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.2557 - accuracy: 0.9833 - val_loss: 0.3238 - val_accuracy: 0.9000\n",
            "Epoch 87/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.2524 - accuracy: 0.9833 - val_loss: 0.3155 - val_accuracy: 0.9000\n",
            "Epoch 88/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2505 - accuracy: 0.9833 - val_loss: 0.3134 - val_accuracy: 0.9000\n",
            "Epoch 89/200\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.2475 - accuracy: 0.9833 - val_loss: 0.3091 - val_accuracy: 0.9000\n",
            "Epoch 90/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2463 - accuracy: 0.9833 - val_loss: 0.3020 - val_accuracy: 0.9333\n",
            "Epoch 91/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.2424 - accuracy: 0.9833 - val_loss: 0.3072 - val_accuracy: 0.9000\n",
            "Epoch 92/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2411 - accuracy: 0.9833 - val_loss: 0.3115 - val_accuracy: 0.9000\n",
            "Epoch 93/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.2418 - accuracy: 0.9833 - val_loss: 0.2961 - val_accuracy: 0.9333\n",
            "Epoch 94/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.2354 - accuracy: 0.9833 - val_loss: 0.3019 - val_accuracy: 0.9000\n",
            "Epoch 95/200\n",
            "120/120 [==============================] - 0s 187us/step - loss: 0.2335 - accuracy: 0.9833 - val_loss: 0.2951 - val_accuracy: 0.9000\n",
            "Epoch 96/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2313 - accuracy: 0.9833 - val_loss: 0.2936 - val_accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2303 - accuracy: 0.9833 - val_loss: 0.2976 - val_accuracy: 0.9000\n",
            "Epoch 98/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2279 - accuracy: 0.9833 - val_loss: 0.2885 - val_accuracy: 0.9000\n",
            "Epoch 99/200\n",
            "120/120 [==============================] - 0s 174us/step - loss: 0.2252 - accuracy: 0.9833 - val_loss: 0.2842 - val_accuracy: 0.9333\n",
            "Epoch 100/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.2242 - accuracy: 0.9833 - val_loss: 0.2926 - val_accuracy: 0.9000\n",
            "Epoch 101/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.2209 - accuracy: 0.9833 - val_loss: 0.2777 - val_accuracy: 0.9333\n",
            "Epoch 102/200\n",
            "120/120 [==============================] - 0s 152us/step - loss: 0.2197 - accuracy: 0.9833 - val_loss: 0.2785 - val_accuracy: 0.9333\n",
            "Epoch 103/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.2170 - accuracy: 0.9833 - val_loss: 0.2845 - val_accuracy: 0.9000\n",
            "Epoch 104/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.2149 - accuracy: 0.9833 - val_loss: 0.2769 - val_accuracy: 0.9000\n",
            "Epoch 105/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2143 - accuracy: 0.9833 - val_loss: 0.2721 - val_accuracy: 0.9333\n",
            "Epoch 106/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.2121 - accuracy: 0.9833 - val_loss: 0.2764 - val_accuracy: 0.9000\n",
            "Epoch 107/200\n",
            "120/120 [==============================] - 0s 165us/step - loss: 0.2090 - accuracy: 0.9833 - val_loss: 0.2724 - val_accuracy: 0.9000\n",
            "Epoch 108/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.2074 - accuracy: 0.9833 - val_loss: 0.2688 - val_accuracy: 0.9333\n",
            "Epoch 109/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.2064 - accuracy: 0.9833 - val_loss: 0.2677 - val_accuracy: 0.9333\n",
            "Epoch 110/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.2041 - accuracy: 0.9833 - val_loss: 0.2723 - val_accuracy: 0.9000\n",
            "Epoch 111/200\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.2029 - accuracy: 0.9833 - val_loss: 0.2602 - val_accuracy: 0.9333\n",
            "Epoch 112/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.2013 - accuracy: 0.9833 - val_loss: 0.2635 - val_accuracy: 0.9333\n",
            "Epoch 113/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.1998 - accuracy: 0.9833 - val_loss: 0.2689 - val_accuracy: 0.9000\n",
            "Epoch 114/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.1984 - accuracy: 0.9833 - val_loss: 0.2516 - val_accuracy: 0.9333\n",
            "Epoch 115/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1981 - accuracy: 0.9833 - val_loss: 0.2517 - val_accuracy: 0.9333\n",
            "Epoch 116/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.1946 - accuracy: 0.9833 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
            "Epoch 117/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.1934 - accuracy: 0.9833 - val_loss: 0.2595 - val_accuracy: 0.9000\n",
            "Epoch 118/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.1926 - accuracy: 0.9833 - val_loss: 0.2456 - val_accuracy: 0.9333\n",
            "Epoch 119/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.1888 - accuracy: 0.9833 - val_loss: 0.2536 - val_accuracy: 0.9333\n",
            "Epoch 120/200\n",
            "120/120 [==============================] - 0s 130us/step - loss: 0.1881 - accuracy: 0.9833 - val_loss: 0.2512 - val_accuracy: 0.9333\n",
            "Epoch 121/200\n",
            "120/120 [==============================] - 0s 127us/step - loss: 0.1866 - accuracy: 0.9833 - val_loss: 0.2469 - val_accuracy: 0.9333\n",
            "Epoch 122/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.1847 - accuracy: 0.9833 - val_loss: 0.2460 - val_accuracy: 0.9333\n",
            "Epoch 123/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.1831 - accuracy: 0.9833 - val_loss: 0.2502 - val_accuracy: 0.9000\n",
            "Epoch 124/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.1823 - accuracy: 0.9833 - val_loss: 0.2467 - val_accuracy: 0.9333\n",
            "Epoch 125/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.1801 - accuracy: 0.9833 - val_loss: 0.2393 - val_accuracy: 0.9333\n",
            "Epoch 126/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.1799 - accuracy: 0.9833 - val_loss: 0.2461 - val_accuracy: 0.9000\n",
            "Epoch 127/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.1772 - accuracy: 0.9833 - val_loss: 0.2406 - val_accuracy: 0.9333\n",
            "Epoch 128/200\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.1770 - accuracy: 0.9833 - val_loss: 0.2340 - val_accuracy: 0.9333\n",
            "Epoch 129/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.1747 - accuracy: 0.9833 - val_loss: 0.2357 - val_accuracy: 0.9333\n",
            "Epoch 130/200\n",
            "120/120 [==============================] - 0s 168us/step - loss: 0.1737 - accuracy: 0.9833 - val_loss: 0.2368 - val_accuracy: 0.9333\n",
            "Epoch 131/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.1721 - accuracy: 0.9833 - val_loss: 0.2334 - val_accuracy: 0.9333\n",
            "Epoch 132/200\n",
            "120/120 [==============================] - 0s 158us/step - loss: 0.1723 - accuracy: 0.9833 - val_loss: 0.2361 - val_accuracy: 0.9333\n",
            "Epoch 133/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1694 - accuracy: 0.9833 - val_loss: 0.2282 - val_accuracy: 0.9333\n",
            "Epoch 134/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.1689 - accuracy: 0.9833 - val_loss: 0.2284 - val_accuracy: 0.9333\n",
            "Epoch 135/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.1673 - accuracy: 0.9833 - val_loss: 0.2251 - val_accuracy: 0.9333\n",
            "Epoch 136/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.1697 - accuracy: 0.9833 - val_loss: 0.2372 - val_accuracy: 0.9000\n",
            "Epoch 137/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.1654 - accuracy: 0.9833 - val_loss: 0.2222 - val_accuracy: 0.9333\n",
            "Epoch 138/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.1638 - accuracy: 0.9833 - val_loss: 0.2241 - val_accuracy: 0.9333\n",
            "Epoch 139/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.1626 - accuracy: 0.9833 - val_loss: 0.2268 - val_accuracy: 0.9333\n",
            "Epoch 140/200\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.1618 - accuracy: 0.9833 - val_loss: 0.2255 - val_accuracy: 0.9333\n",
            "Epoch 141/200\n",
            "120/120 [==============================] - 0s 174us/step - loss: 0.1604 - accuracy: 0.9833 - val_loss: 0.2221 - val_accuracy: 0.9333\n",
            "Epoch 142/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.1594 - accuracy: 0.9833 - val_loss: 0.2244 - val_accuracy: 0.9333\n",
            "Epoch 143/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.1581 - accuracy: 0.9833 - val_loss: 0.2200 - val_accuracy: 0.9333\n",
            "Epoch 144/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.1569 - accuracy: 0.9833 - val_loss: 0.2194 - val_accuracy: 0.9333\n",
            "Epoch 145/200\n",
            "120/120 [==============================] - 0s 142us/step - loss: 0.1569 - accuracy: 0.9833 - val_loss: 0.2150 - val_accuracy: 0.9333\n",
            "Epoch 146/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.1558 - accuracy: 0.9833 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
            "Epoch 147/200\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.1540 - accuracy: 0.9833 - val_loss: 0.2156 - val_accuracy: 0.9333\n",
            "Epoch 148/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1532 - accuracy: 0.9833 - val_loss: 0.2160 - val_accuracy: 0.9333\n",
            "Epoch 149/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.1523 - accuracy: 0.9833 - val_loss: 0.2120 - val_accuracy: 0.9333\n",
            "Epoch 150/200\n",
            "120/120 [==============================] - 0s 131us/step - loss: 0.1516 - accuracy: 0.9833 - val_loss: 0.2075 - val_accuracy: 0.9333\n",
            "Epoch 151/200\n",
            "120/120 [==============================] - 0s 168us/step - loss: 0.1503 - accuracy: 0.9833 - val_loss: 0.2149 - val_accuracy: 0.9333\n",
            "Epoch 152/200\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.1498 - accuracy: 0.9833 - val_loss: 0.2092 - val_accuracy: 0.9333\n",
            "Epoch 153/200\n",
            "120/120 [==============================] - 0s 164us/step - loss: 0.1480 - accuracy: 0.9833 - val_loss: 0.2133 - val_accuracy: 0.9333\n",
            "Epoch 154/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.1476 - accuracy: 0.9833 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
            "Epoch 155/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1467 - accuracy: 0.9833 - val_loss: 0.2078 - val_accuracy: 0.9333\n",
            "Epoch 156/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.1480 - accuracy: 0.9833 - val_loss: 0.2162 - val_accuracy: 0.9000\n",
            "Epoch 157/200\n",
            "120/120 [==============================] - 0s 160us/step - loss: 0.1471 - accuracy: 0.9833 - val_loss: 0.1967 - val_accuracy: 0.9667\n",
            "Epoch 158/200\n",
            "120/120 [==============================] - 0s 175us/step - loss: 0.1453 - accuracy: 0.9833 - val_loss: 0.2111 - val_accuracy: 0.9333\n",
            "Epoch 159/200\n",
            "120/120 [==============================] - 0s 154us/step - loss: 0.1443 - accuracy: 0.9833 - val_loss: 0.2012 - val_accuracy: 0.9333\n",
            "Epoch 160/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.1462 - accuracy: 0.9833 - val_loss: 0.2149 - val_accuracy: 0.9000\n",
            "Epoch 161/200\n",
            "120/120 [==============================] - 0s 141us/step - loss: 0.1407 - accuracy: 0.9833 - val_loss: 0.1976 - val_accuracy: 0.9667\n",
            "Epoch 162/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.1423 - accuracy: 0.9833 - val_loss: 0.1958 - val_accuracy: 0.9667\n",
            "Epoch 163/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.1396 - accuracy: 0.9833 - val_loss: 0.2081 - val_accuracy: 0.9333\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.1384 - accuracy: 0.9833 - val_loss: 0.2036 - val_accuracy: 0.9333\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.1380 - accuracy: 0.9833 - val_loss: 0.1968 - val_accuracy: 0.9667\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.1372 - accuracy: 0.9833 - val_loss: 0.1970 - val_accuracy: 0.9333\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.1361 - accuracy: 0.9833 - val_loss: 0.2017 - val_accuracy: 0.9333\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1355 - accuracy: 0.9833 - val_loss: 0.2001 - val_accuracy: 0.9333\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1344 - accuracy: 0.9833 - val_loss: 0.1991 - val_accuracy: 0.9333\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.1357 - accuracy: 0.9833 - val_loss: 0.1880 - val_accuracy: 0.9667\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 0s 153us/step - loss: 0.1328 - accuracy: 0.9833 - val_loss: 0.1997 - val_accuracy: 0.9333\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 0s 156us/step - loss: 0.1327 - accuracy: 0.9833 - val_loss: 0.1943 - val_accuracy: 0.9333\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.1336 - accuracy: 0.9833 - val_loss: 0.1987 - val_accuracy: 0.9333\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.1301 - accuracy: 0.9833 - val_loss: 0.1877 - val_accuracy: 0.9667\n",
            "Epoch 175/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.1305 - accuracy: 0.9833 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
            "Epoch 176/200\n",
            "120/120 [==============================] - 0s 133us/step - loss: 0.1300 - accuracy: 0.9833 - val_loss: 0.1934 - val_accuracy: 0.9333\n",
            "Epoch 177/200\n",
            "120/120 [==============================] - 0s 147us/step - loss: 0.1289 - accuracy: 0.9833 - val_loss: 0.1887 - val_accuracy: 0.9667\n",
            "Epoch 178/200\n",
            "120/120 [==============================] - 0s 149us/step - loss: 0.1280 - accuracy: 0.9833 - val_loss: 0.1850 - val_accuracy: 0.9667\n",
            "Epoch 179/200\n",
            "120/120 [==============================] - 0s 135us/step - loss: 0.1272 - accuracy: 0.9833 - val_loss: 0.1890 - val_accuracy: 0.9667\n",
            "Epoch 180/200\n",
            "120/120 [==============================] - 0s 151us/step - loss: 0.1262 - accuracy: 0.9833 - val_loss: 0.1895 - val_accuracy: 0.9333\n",
            "Epoch 181/200\n",
            "120/120 [==============================] - 0s 140us/step - loss: 0.1271 - accuracy: 0.9833 - val_loss: 0.1940 - val_accuracy: 0.9333\n",
            "Epoch 182/200\n",
            "120/120 [==============================] - 0s 132us/step - loss: 0.1263 - accuracy: 0.9833 - val_loss: 0.1817 - val_accuracy: 0.9667\n",
            "Epoch 183/200\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.1253 - accuracy: 0.9833 - val_loss: 0.1888 - val_accuracy: 0.9333\n",
            "Epoch 184/200\n",
            "120/120 [==============================] - 0s 160us/step - loss: 0.1251 - accuracy: 0.9833 - val_loss: 0.1829 - val_accuracy: 0.9667\n",
            "Epoch 185/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.1251 - accuracy: 0.9833 - val_loss: 0.1788 - val_accuracy: 0.9667\n",
            "Epoch 186/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.1230 - accuracy: 0.9833 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
            "Epoch 187/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.1220 - accuracy: 0.9833 - val_loss: 0.1856 - val_accuracy: 0.9333\n",
            "Epoch 188/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.1225 - accuracy: 0.9833 - val_loss: 0.1819 - val_accuracy: 0.9667\n",
            "Epoch 189/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.1211 - accuracy: 0.9833 - val_loss: 0.1798 - val_accuracy: 0.9667\n",
            "Epoch 190/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.1205 - accuracy: 0.9833 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
            "Epoch 191/200\n",
            "120/120 [==============================] - 0s 146us/step - loss: 0.1201 - accuracy: 0.9833 - val_loss: 0.1855 - val_accuracy: 0.9333\n",
            "Epoch 192/200\n",
            "120/120 [==============================] - 0s 136us/step - loss: 0.1204 - accuracy: 0.9833 - val_loss: 0.1718 - val_accuracy: 0.9667\n",
            "Epoch 193/200\n",
            "120/120 [==============================] - 0s 138us/step - loss: 0.1187 - accuracy: 0.9833 - val_loss: 0.1808 - val_accuracy: 0.9667\n",
            "Epoch 194/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.1182 - accuracy: 0.9833 - val_loss: 0.1834 - val_accuracy: 0.9333\n",
            "Epoch 195/200\n",
            "120/120 [==============================] - 0s 145us/step - loss: 0.1175 - accuracy: 0.9833 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
            "Epoch 196/200\n",
            "120/120 [==============================] - 0s 134us/step - loss: 0.1174 - accuracy: 0.9833 - val_loss: 0.1789 - val_accuracy: 0.9667\n",
            "Epoch 197/200\n",
            "120/120 [==============================] - 0s 167us/step - loss: 0.1160 - accuracy: 0.9833 - val_loss: 0.1792 - val_accuracy: 0.9667\n",
            "Epoch 198/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.1167 - accuracy: 0.9833 - val_loss: 0.1825 - val_accuracy: 0.9333\n",
            "Epoch 199/200\n",
            "120/120 [==============================] - 0s 150us/step - loss: 0.1145 - accuracy: 0.9833 - val_loss: 0.1758 - val_accuracy: 0.9667\n",
            "Epoch 200/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.1142 - accuracy: 0.9833 - val_loss: 0.1718 - val_accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zMiHHnT6_H6",
        "colab_type": "text"
      },
      "source": [
        "학습 결과 그려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chz7ff2q7ABg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "7f1f6d31-e7b9-4b06-f81d-528443fb1476"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his_dict = history.history\n",
        "loss = his_dict['loss']\n",
        "val_loss = his_dict['val_loss'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# 훈련 및 검증 손실 그리기\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n",
        "ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')\n",
        "ax1.set_title('train and val loss')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.legend()\n",
        "\n",
        "acc = his_dict['accuracy']\n",
        "val_acc = his_dict['val_accuracy']\n",
        "\n",
        "# 훈련 및 검증 정확도 그리기\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, acc, color = 'blue', label = 'train_acc')\n",
        "ax2.plot(epochs, val_acc, color = 'orange', label = 'val_acc')\n",
        "ax2.set_title('train and val acc')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('acc')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quFgJddF7Kp9",
        "colab_type": "text"
      },
      "source": [
        "모델 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stoUDFEJ7LXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2def581e-0501-4c30-d2f3-8d960a275fb8"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 38us/step\n",
            "accuracy: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}