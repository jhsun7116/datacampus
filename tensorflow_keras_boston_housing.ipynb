{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0724_04_boston.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxG5n7eGrgKI",
        "colab_type": "text"
      },
      "source": [
        "보스턴 주택 가격 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHE7uiGTrWw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9a9c5636-91d9-40ae-9653-9fbcbf2a6fd0"
      },
      "source": [
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "\n",
        "# 데이터를 다운받습니다.\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)\n",
        "\n",
        "# 총 데이터 506에서 테스트 스플릿 0.2 0.8 이라서 8:2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikpnH0SKrl5D",
        "colab_type": "text"
      },
      "source": [
        "데이터 형태 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CByS_LnWsJTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7efb392b-b283-482d-dc31-ac04a189ed82"
      },
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13) (404,)\n",
            "(102, 13) (102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdUq-hIVsmjl",
        "colab_type": "text"
      },
      "source": [
        "데이터 전처리 및 검증 데이터셋 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEHrWR9RsoVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터 표준화 (Standardization)\n",
        "mean = np.mean(x_train, axis = 0) #평균\n",
        "std = np.std(x_train, axis = 0) #표준편차\n",
        "\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "# 검증 데이터셋을 만듭니다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
        "                                                  test_size = 0.33, \n",
        "                                                  random_state = 777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUn9zIHth-N",
        "colab_type": "text"
      },
      "source": [
        "모델 구성 및 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spPumFMotkTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 모델 구성하기\n",
        "model = Sequential()\n",
        "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
        "# 13차원의 데이터를 입력으로 받고, 64개의 출력을 가지는 첫 번째 Dense 층\n",
        "model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "model.add(Dense(32, activation = 'relu')) # 32개의 출력을 가지는 Dense 층\n",
        "model.add(Dense(1)) # 하나의 값을 출력합니다. -> 활성화함수를 설정하지 않으면 기본 활성화 함수 : linear로 출력\n",
        "\n",
        "# 모델 설정하기\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics=['mae', 'mse']) # mae(Mean Absolute Error) : 평균 절대 오차, mse(Mean Squared Error) : 평균 제곱 오차"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUGVcrZ0u2gP",
        "colab_type": "text"
      },
      "source": [
        "모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUrlearPu3TE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e609077f-804b-476f-ace2-6b45bde2734a"
      },
      "source": [
        "history = model.fit(x_train, y_train, \n",
        "                    epochs = 300, \n",
        "                    validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 552.6546 - mae: 21.8970 - mse: 552.6546 - val_loss: 603.5472 - val_mae: 22.4138 - val_mse: 603.5472\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 525.8315 - mae: 21.2956 - mse: 525.8315 - val_loss: 573.6225 - val_mae: 21.7752 - val_mse: 573.6225\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 496.9054 - mae: 20.6413 - mse: 496.9054 - val_loss: 540.0347 - val_mae: 21.0376 - val_mse: 540.0347\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 463.0936 - mae: 19.8573 - mse: 463.0936 - val_loss: 501.0312 - val_mae: 20.1487 - val_mse: 501.0312\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 424.7066 - mae: 18.9021 - mse: 424.7066 - val_loss: 454.6311 - val_mae: 19.0491 - val_mse: 454.6311\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 378.2802 - mae: 17.7265 - mse: 378.2802 - val_loss: 401.1474 - val_mae: 17.7037 - val_mse: 401.1474\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 327.8225 - mae: 16.3619 - mse: 327.8225 - val_loss: 340.8252 - val_mae: 16.0596 - val_mse: 340.8252\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 270.2508 - mae: 14.6986 - mse: 270.2508 - val_loss: 277.6919 - val_mae: 14.1609 - val_mse: 277.6919\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 210.9535 - mae: 12.7939 - mse: 210.9535 - val_loss: 216.5596 - val_mae: 12.0588 - val_mse: 216.5596\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 158.4504 - mae: 10.8094 - mse: 158.4504 - val_loss: 162.1367 - val_mae: 10.0665 - val_mse: 162.1367\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 113.2239 - mae: 8.8649 - mse: 113.2239 - val_loss: 123.2211 - val_mae: 8.5910 - val_mse: 123.2211\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 83.5802 - mae: 7.4217 - mse: 83.5802 - val_loss: 97.0846 - val_mae: 7.5908 - val_mse: 97.0846\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 63.9789 - mae: 6.4520 - mse: 63.9789 - val_loss: 80.9369 - val_mae: 6.8310 - val_mse: 80.9369\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 53.2996 - mae: 5.8158 - mse: 53.2996 - val_loss: 68.5464 - val_mae: 6.2390 - val_mse: 68.5464\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 44.1945 - mae: 5.2667 - mse: 44.1945 - val_loss: 59.2055 - val_mae: 5.7708 - val_mse: 59.2055\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 38.0223 - mae: 4.8127 - mse: 38.0223 - val_loss: 51.4696 - val_mae: 5.3331 - val_mse: 51.4696\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32.9138 - mae: 4.4208 - mse: 32.9138 - val_loss: 45.6718 - val_mae: 4.9492 - val_mse: 45.6718\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 29.2869 - mae: 4.1047 - mse: 29.2869 - val_loss: 41.4387 - val_mae: 4.6766 - val_mse: 41.4387\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 26.7248 - mae: 3.8677 - mse: 26.7248 - val_loss: 38.2967 - val_mae: 4.4701 - val_mse: 38.2967\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 25.0184 - mae: 3.6859 - mse: 25.0184 - val_loss: 35.9451 - val_mae: 4.3061 - val_mse: 35.9451\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 23.4821 - mae: 3.5074 - mse: 23.4821 - val_loss: 33.9315 - val_mae: 4.1312 - val_mse: 33.9315\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.5434 - mae: 3.3826 - mse: 22.5434 - val_loss: 32.2343 - val_mae: 3.9769 - val_mse: 32.2343\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.6937 - mae: 3.2789 - mse: 21.6937 - val_loss: 31.0838 - val_mae: 3.8878 - val_mse: 31.0838\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.0221 - mae: 3.2019 - mse: 21.0221 - val_loss: 30.0402 - val_mae: 3.8109 - val_mse: 30.0402\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.4655 - mae: 3.1527 - mse: 20.4655 - val_loss: 29.1737 - val_mae: 3.7357 - val_mse: 29.1737\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.0631 - mae: 3.1182 - mse: 20.0631 - val_loss: 28.3560 - val_mae: 3.6977 - val_mse: 28.3560\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.5467 - mae: 3.0820 - mse: 19.5467 - val_loss: 27.8874 - val_mae: 3.6610 - val_mse: 27.8874\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.1902 - mae: 3.0567 - mse: 19.1902 - val_loss: 27.3652 - val_mae: 3.6240 - val_mse: 27.3652\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.8324 - mae: 3.0244 - mse: 18.8324 - val_loss: 26.7674 - val_mae: 3.5848 - val_mse: 26.7674\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.4552 - mae: 2.9937 - mse: 18.4552 - val_loss: 26.2978 - val_mae: 3.5520 - val_mse: 26.2978\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.1747 - mae: 2.9589 - mse: 18.1747 - val_loss: 26.1173 - val_mae: 3.5178 - val_mse: 26.1173\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.7552 - mae: 2.9181 - mse: 17.7552 - val_loss: 25.4448 - val_mae: 3.4567 - val_mse: 25.4448\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.5262 - mae: 2.8968 - mse: 17.5262 - val_loss: 24.9478 - val_mae: 3.4329 - val_mse: 24.9478\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.1919 - mae: 2.8687 - mse: 17.1919 - val_loss: 24.8617 - val_mae: 3.4196 - val_mse: 24.8617\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.9741 - mae: 2.8488 - mse: 16.9741 - val_loss: 24.3488 - val_mae: 3.3947 - val_mse: 24.3488\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.6097 - mae: 2.8180 - mse: 16.6097 - val_loss: 24.0911 - val_mae: 3.3651 - val_mse: 24.0911\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.3621 - mae: 2.7881 - mse: 16.3621 - val_loss: 23.7540 - val_mae: 3.3338 - val_mse: 23.7540\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.1409 - mae: 2.7616 - mse: 16.1409 - val_loss: 23.4423 - val_mae: 3.3117 - val_mse: 23.4423\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.8939 - mae: 2.7387 - mse: 15.8939 - val_loss: 23.0202 - val_mae: 3.2842 - val_mse: 23.0202\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.6767 - mae: 2.7144 - mse: 15.6767 - val_loss: 22.3709 - val_mae: 3.2188 - val_mse: 22.3709\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.4388 - mae: 2.6874 - mse: 15.4388 - val_loss: 22.3808 - val_mae: 3.2237 - val_mse: 22.3808\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.2563 - mae: 2.6716 - mse: 15.2563 - val_loss: 22.2897 - val_mae: 3.2466 - val_mse: 22.2897\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.9836 - mae: 2.6446 - mse: 14.9836 - val_loss: 21.8253 - val_mae: 3.2078 - val_mse: 21.8253\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8785 - mae: 2.6455 - mse: 14.8785 - val_loss: 21.3142 - val_mae: 3.1946 - val_mse: 21.3142\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.6659 - mae: 2.6379 - mse: 14.6659 - val_loss: 20.7339 - val_mae: 3.1474 - val_mse: 20.7339\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.3717 - mae: 2.6079 - mse: 14.3717 - val_loss: 20.6588 - val_mae: 3.1401 - val_mse: 20.6588\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.1701 - mae: 2.5828 - mse: 14.1701 - val_loss: 20.5859 - val_mae: 3.1315 - val_mse: 20.5859\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.9820 - mae: 2.5561 - mse: 13.9820 - val_loss: 20.5340 - val_mae: 3.1024 - val_mse: 20.5340\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.8233 - mae: 2.5354 - mse: 13.8233 - val_loss: 20.1931 - val_mae: 3.0790 - val_mse: 20.1931\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.6775 - mae: 2.5263 - mse: 13.6775 - val_loss: 19.8568 - val_mae: 3.0614 - val_mse: 19.8568\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.4573 - mae: 2.5083 - mse: 13.4573 - val_loss: 19.6459 - val_mae: 3.0373 - val_mse: 19.6459\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.3342 - mae: 2.4910 - mse: 13.3342 - val_loss: 19.5525 - val_mae: 3.0336 - val_mse: 19.5525\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.1661 - mae: 2.4696 - mse: 13.1661 - val_loss: 19.4029 - val_mae: 3.0165 - val_mse: 19.4029\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.0602 - mae: 2.4537 - mse: 13.0602 - val_loss: 19.1656 - val_mae: 3.0071 - val_mse: 19.1656\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.9025 - mae: 2.4388 - mse: 12.9025 - val_loss: 18.9443 - val_mae: 2.9865 - val_mse: 18.9443\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.8048 - mae: 2.4320 - mse: 12.8048 - val_loss: 18.7408 - val_mae: 2.9835 - val_mse: 18.7408\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6760 - mae: 2.4162 - mse: 12.6760 - val_loss: 18.7154 - val_mae: 2.9688 - val_mse: 18.7154\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5814 - mae: 2.4043 - mse: 12.5814 - val_loss: 18.4673 - val_mae: 2.9495 - val_mse: 18.4673\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4284 - mae: 2.3927 - mse: 12.4284 - val_loss: 18.0926 - val_mae: 2.9234 - val_mse: 18.0926\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3324 - mae: 2.3832 - mse: 12.3324 - val_loss: 17.9432 - val_mae: 2.9033 - val_mse: 17.9432\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.2304 - mae: 2.3711 - mse: 12.2304 - val_loss: 18.1004 - val_mae: 2.9331 - val_mse: 18.1004\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1432 - mae: 2.3692 - mse: 12.1432 - val_loss: 17.8896 - val_mae: 2.9118 - val_mse: 17.8896\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0579 - mae: 2.3669 - mse: 12.0579 - val_loss: 17.7327 - val_mae: 2.8930 - val_mse: 17.7327\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9506 - mae: 2.3518 - mse: 11.9506 - val_loss: 17.8584 - val_mae: 2.9060 - val_mse: 17.8584\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.9124 - mae: 2.3459 - mse: 11.9124 - val_loss: 17.9148 - val_mae: 2.9167 - val_mse: 17.9148\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.8243 - mae: 2.3421 - mse: 11.8243 - val_loss: 17.3533 - val_mae: 2.8653 - val_mse: 17.3533\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.8500 - mae: 2.3549 - mse: 11.8500 - val_loss: 17.2743 - val_mae: 2.8322 - val_mse: 17.2743\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7241 - mae: 2.3397 - mse: 11.7241 - val_loss: 17.3197 - val_mae: 2.8624 - val_mse: 17.3197\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5741 - mae: 2.3194 - mse: 11.5741 - val_loss: 17.1479 - val_mae: 2.8345 - val_mse: 17.1479\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5542 - mae: 2.3159 - mse: 11.5542 - val_loss: 17.2036 - val_mae: 2.8247 - val_mse: 17.2036\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4623 - mae: 2.3125 - mse: 11.4623 - val_loss: 16.9696 - val_mae: 2.8169 - val_mse: 16.9696\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4256 - mae: 2.3233 - mse: 11.4256 - val_loss: 16.7854 - val_mae: 2.8240 - val_mse: 16.7854\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.2945 - mae: 2.3030 - mse: 11.2945 - val_loss: 16.7808 - val_mae: 2.8032 - val_mse: 16.7808\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2244 - mae: 2.2827 - mse: 11.2244 - val_loss: 16.8708 - val_mae: 2.8126 - val_mse: 16.8708\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1419 - mae: 2.2827 - mse: 11.1419 - val_loss: 16.5954 - val_mae: 2.7933 - val_mse: 16.5954\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0982 - mae: 2.2885 - mse: 11.0982 - val_loss: 16.5283 - val_mae: 2.7908 - val_mse: 16.5283\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0761 - mae: 2.2829 - mse: 11.0761 - val_loss: 16.6191 - val_mae: 2.7999 - val_mse: 16.6191\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9953 - mae: 2.2734 - mse: 10.9953 - val_loss: 16.1747 - val_mae: 2.7555 - val_mse: 16.1747\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9664 - mae: 2.2712 - mse: 10.9664 - val_loss: 16.0080 - val_mae: 2.7333 - val_mse: 16.0080\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.9250 - mae: 2.2666 - mse: 10.9250 - val_loss: 16.1298 - val_mae: 2.7614 - val_mse: 16.1298\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8706 - mae: 2.2547 - mse: 10.8706 - val_loss: 15.9604 - val_mae: 2.7370 - val_mse: 15.9604\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7887 - mae: 2.2451 - mse: 10.7887 - val_loss: 16.2305 - val_mae: 2.7668 - val_mse: 16.2305\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7511 - mae: 2.2398 - mse: 10.7511 - val_loss: 16.0762 - val_mae: 2.7476 - val_mse: 16.0762\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7283 - mae: 2.2417 - mse: 10.7283 - val_loss: 15.9212 - val_mae: 2.7406 - val_mse: 15.9212\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6770 - mae: 2.2422 - mse: 10.6770 - val_loss: 15.9464 - val_mae: 2.7555 - val_mse: 15.9464\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5722 - mae: 2.2367 - mse: 10.5722 - val_loss: 15.8332 - val_mae: 2.7440 - val_mse: 15.8332\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5796 - mae: 2.2162 - mse: 10.5796 - val_loss: 15.8972 - val_mae: 2.7287 - val_mse: 15.8972\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4722 - mae: 2.2161 - mse: 10.4722 - val_loss: 15.7255 - val_mae: 2.7459 - val_mse: 15.7255\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4455 - mae: 2.2250 - mse: 10.4455 - val_loss: 15.5096 - val_mae: 2.7064 - val_mse: 15.5096\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4349 - mae: 2.2173 - mse: 10.4349 - val_loss: 15.5561 - val_mae: 2.7007 - val_mse: 15.5561\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3572 - mae: 2.2028 - mse: 10.3572 - val_loss: 15.7257 - val_mae: 2.7425 - val_mse: 15.7257\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3167 - mae: 2.2037 - mse: 10.3167 - val_loss: 15.5320 - val_mae: 2.7328 - val_mse: 15.5320\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2688 - mae: 2.2093 - mse: 10.2688 - val_loss: 15.4307 - val_mae: 2.7165 - val_mse: 15.4307\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.2179 - mae: 2.1976 - mse: 10.2179 - val_loss: 15.3598 - val_mae: 2.6906 - val_mse: 15.3598\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1915 - mae: 2.1995 - mse: 10.1915 - val_loss: 15.1911 - val_mae: 2.6850 - val_mse: 15.1911\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1619 - mae: 2.1946 - mse: 10.1619 - val_loss: 15.1811 - val_mae: 2.6945 - val_mse: 15.1811\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1141 - mae: 2.1863 - mse: 10.1141 - val_loss: 15.5651 - val_mae: 2.7234 - val_mse: 15.5651\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0351 - mae: 2.1795 - mse: 10.0351 - val_loss: 15.2520 - val_mae: 2.6917 - val_mse: 15.2520\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0174 - mae: 2.1998 - mse: 10.0174 - val_loss: 15.1240 - val_mae: 2.7075 - val_mse: 15.1240\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9956 - mae: 2.1884 - mse: 9.9956 - val_loss: 15.0500 - val_mae: 2.6803 - val_mse: 15.0500\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9098 - mae: 2.1697 - mse: 9.9098 - val_loss: 15.0458 - val_mae: 2.6749 - val_mse: 15.0458\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8795 - mae: 2.1815 - mse: 9.8795 - val_loss: 14.8829 - val_mae: 2.6806 - val_mse: 14.8829\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8400 - mae: 2.1825 - mse: 9.8400 - val_loss: 14.9498 - val_mae: 2.6753 - val_mse: 14.9498\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8411 - mae: 2.1537 - mse: 9.8411 - val_loss: 15.1552 - val_mae: 2.6664 - val_mse: 15.1552\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8202 - mae: 2.1489 - mse: 9.8202 - val_loss: 14.9800 - val_mae: 2.6736 - val_mse: 14.9800\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6996 - mae: 2.1529 - mse: 9.6996 - val_loss: 14.9053 - val_mae: 2.6650 - val_mse: 14.9053\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7062 - mae: 2.1518 - mse: 9.7062 - val_loss: 14.8992 - val_mae: 2.6605 - val_mse: 14.8992\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6799 - mae: 2.1580 - mse: 9.6799 - val_loss: 14.6179 - val_mae: 2.6485 - val_mse: 14.6179\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6154 - mae: 2.1479 - mse: 9.6154 - val_loss: 14.8764 - val_mae: 2.6532 - val_mse: 14.8764\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6129 - mae: 2.1435 - mse: 9.6129 - val_loss: 15.0024 - val_mae: 2.6805 - val_mse: 15.0024\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.5457 - mae: 2.1383 - mse: 9.5457 - val_loss: 14.5328 - val_mae: 2.6223 - val_mse: 14.5328\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5205 - mae: 2.1423 - mse: 9.5205 - val_loss: 14.8259 - val_mae: 2.6500 - val_mse: 14.8259\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4452 - mae: 2.1315 - mse: 9.4452 - val_loss: 14.7496 - val_mae: 2.6526 - val_mse: 14.7496\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4089 - mae: 2.1293 - mse: 9.4089 - val_loss: 14.9597 - val_mae: 2.6752 - val_mse: 14.9597\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3713 - mae: 2.1266 - mse: 9.3713 - val_loss: 14.5390 - val_mae: 2.6344 - val_mse: 14.5390\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3816 - mae: 2.1197 - mse: 9.3816 - val_loss: 14.6465 - val_mae: 2.6300 - val_mse: 14.6465\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4809 - mae: 2.1466 - mse: 9.4809 - val_loss: 14.5990 - val_mae: 2.6739 - val_mse: 14.5990\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3738 - mae: 2.1243 - mse: 9.3738 - val_loss: 14.6283 - val_mae: 2.6340 - val_mse: 14.6283\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3895 - mae: 2.1281 - mse: 9.3895 - val_loss: 14.3292 - val_mae: 2.6315 - val_mse: 14.3292\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1775 - mae: 2.1163 - mse: 9.1775 - val_loss: 14.0228 - val_mae: 2.5919 - val_mse: 14.0228\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1530 - mae: 2.1103 - mse: 9.1530 - val_loss: 14.2279 - val_mae: 2.6042 - val_mse: 14.2279\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1732 - mae: 2.1101 - mse: 9.1732 - val_loss: 14.2821 - val_mae: 2.6190 - val_mse: 14.2821\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0777 - mae: 2.0995 - mse: 9.0777 - val_loss: 14.3907 - val_mae: 2.6144 - val_mse: 14.3907\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1037 - mae: 2.1046 - mse: 9.1037 - val_loss: 14.3237 - val_mae: 2.6282 - val_mse: 14.3237\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0171 - mae: 2.0964 - mse: 9.0171 - val_loss: 14.2457 - val_mae: 2.6006 - val_mse: 14.2457\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0420 - mae: 2.0895 - mse: 9.0420 - val_loss: 14.4019 - val_mae: 2.6136 - val_mse: 14.4019\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9432 - mae: 2.0863 - mse: 8.9432 - val_loss: 14.2499 - val_mae: 2.6172 - val_mse: 14.2499\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9200 - mae: 2.0942 - mse: 8.9200 - val_loss: 14.0787 - val_mae: 2.6044 - val_mse: 14.0787\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9578 - mae: 2.1076 - mse: 8.9578 - val_loss: 14.0254 - val_mae: 2.6012 - val_mse: 14.0254\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.0215 - mae: 2.0816 - mse: 9.0215 - val_loss: 14.3679 - val_mae: 2.5852 - val_mse: 14.3679\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8342 - mae: 2.0782 - mse: 8.8342 - val_loss: 14.0487 - val_mae: 2.5993 - val_mse: 14.0487\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8130 - mae: 2.0932 - mse: 8.8130 - val_loss: 13.9931 - val_mae: 2.6039 - val_mse: 13.9931\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7828 - mae: 2.0852 - mse: 8.7828 - val_loss: 13.9727 - val_mae: 2.5865 - val_mse: 13.9727\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7409 - mae: 2.0693 - mse: 8.7409 - val_loss: 13.9101 - val_mae: 2.5663 - val_mse: 13.9101\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7310 - mae: 2.0729 - mse: 8.7310 - val_loss: 14.0148 - val_mae: 2.5978 - val_mse: 14.0148\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6605 - mae: 2.0671 - mse: 8.6605 - val_loss: 14.0517 - val_mae: 2.5979 - val_mse: 14.0517\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6310 - mae: 2.0734 - mse: 8.6310 - val_loss: 13.7626 - val_mae: 2.5660 - val_mse: 13.7626\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5990 - mae: 2.0726 - mse: 8.5990 - val_loss: 13.9218 - val_mae: 2.5870 - val_mse: 13.9218\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5662 - mae: 2.0572 - mse: 8.5662 - val_loss: 14.0730 - val_mae: 2.5964 - val_mse: 14.0730\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6380 - mae: 2.0690 - mse: 8.6380 - val_loss: 13.6266 - val_mae: 2.5574 - val_mse: 13.6266\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4522 - mae: 2.0519 - mse: 8.4522 - val_loss: 13.9430 - val_mae: 2.5619 - val_mse: 13.9430\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.5688 - mae: 2.0386 - mse: 8.5688 - val_loss: 14.0039 - val_mae: 2.5844 - val_mse: 14.0039\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6008 - mae: 2.0486 - mse: 8.6008 - val_loss: 13.6058 - val_mae: 2.5443 - val_mse: 13.6058\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5496 - mae: 2.0480 - mse: 8.5496 - val_loss: 14.0964 - val_mae: 2.6011 - val_mse: 14.0964\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3933 - mae: 2.0471 - mse: 8.3933 - val_loss: 13.5517 - val_mae: 2.5525 - val_mse: 13.5517\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4194 - mae: 2.0544 - mse: 8.4194 - val_loss: 13.6290 - val_mae: 2.5564 - val_mse: 13.6290\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4405 - mae: 2.0335 - mse: 8.4405 - val_loss: 14.1602 - val_mae: 2.5768 - val_mse: 14.1602\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3954 - mae: 2.0313 - mse: 8.3954 - val_loss: 13.5870 - val_mae: 2.5314 - val_mse: 13.5870\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3674 - mae: 2.0384 - mse: 8.3674 - val_loss: 13.6023 - val_mae: 2.5607 - val_mse: 13.6023\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2711 - mae: 2.0285 - mse: 8.2711 - val_loss: 13.7057 - val_mae: 2.5588 - val_mse: 13.7057\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2494 - mae: 2.0107 - mse: 8.2494 - val_loss: 13.6179 - val_mae: 2.5442 - val_mse: 13.6179\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1368 - mae: 2.0195 - mse: 8.1368 - val_loss: 13.0880 - val_mae: 2.5212 - val_mse: 13.0880\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1812 - mae: 2.0399 - mse: 8.1812 - val_loss: 13.0927 - val_mae: 2.5084 - val_mse: 13.0927\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1166 - mae: 2.0179 - mse: 8.1166 - val_loss: 13.3164 - val_mae: 2.5357 - val_mse: 13.3164\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1244 - mae: 2.0091 - mse: 8.1244 - val_loss: 13.3696 - val_mae: 2.5276 - val_mse: 13.3696\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0559 - mae: 2.0093 - mse: 8.0559 - val_loss: 13.3538 - val_mae: 2.5322 - val_mse: 13.3538\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0264 - mae: 2.0038 - mse: 8.0264 - val_loss: 13.2758 - val_mae: 2.5237 - val_mse: 13.2758\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9848 - mae: 1.9964 - mse: 7.9848 - val_loss: 12.9785 - val_mae: 2.4988 - val_mse: 12.9785\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9786 - mae: 2.0003 - mse: 7.9786 - val_loss: 12.9745 - val_mae: 2.5010 - val_mse: 12.9745\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9458 - mae: 1.9926 - mse: 7.9458 - val_loss: 12.9798 - val_mae: 2.4992 - val_mse: 12.9798\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9215 - mae: 1.9966 - mse: 7.9215 - val_loss: 12.9723 - val_mae: 2.5062 - val_mse: 12.9723\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8774 - mae: 1.9937 - mse: 7.8774 - val_loss: 12.8904 - val_mae: 2.4888 - val_mse: 12.8904\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8658 - mae: 1.9906 - mse: 7.8658 - val_loss: 13.1177 - val_mae: 2.5182 - val_mse: 13.1177\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9135 - mae: 2.0075 - mse: 7.9135 - val_loss: 12.8720 - val_mae: 2.5166 - val_mse: 12.8720\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8780 - mae: 2.0032 - mse: 7.8780 - val_loss: 13.0056 - val_mae: 2.4950 - val_mse: 13.0056\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7967 - mae: 1.9792 - mse: 7.7967 - val_loss: 13.0036 - val_mae: 2.5147 - val_mse: 13.0036\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7862 - mae: 1.9964 - mse: 7.7862 - val_loss: 13.1055 - val_mae: 2.5151 - val_mse: 13.1055\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7546 - mae: 1.9692 - mse: 7.7546 - val_loss: 13.1310 - val_mae: 2.5125 - val_mse: 13.1310\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7484 - mae: 1.9832 - mse: 7.7484 - val_loss: 12.8703 - val_mae: 2.5026 - val_mse: 12.8703\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7205 - mae: 1.9706 - mse: 7.7205 - val_loss: 12.8654 - val_mae: 2.4836 - val_mse: 12.8654\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7367 - mae: 1.9761 - mse: 7.7367 - val_loss: 12.7050 - val_mae: 2.4741 - val_mse: 12.7050\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6389 - mae: 1.9574 - mse: 7.6389 - val_loss: 12.9930 - val_mae: 2.5075 - val_mse: 12.9930\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6315 - mae: 1.9647 - mse: 7.6315 - val_loss: 12.6225 - val_mae: 2.4616 - val_mse: 12.6225\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5325 - mae: 1.9557 - mse: 7.5325 - val_loss: 12.5784 - val_mae: 2.4636 - val_mse: 12.5784\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5577 - mae: 1.9591 - mse: 7.5577 - val_loss: 12.5979 - val_mae: 2.4760 - val_mse: 12.5979\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5477 - mae: 1.9704 - mse: 7.5477 - val_loss: 12.8720 - val_mae: 2.4932 - val_mse: 12.8720\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6248 - mae: 1.9598 - mse: 7.6248 - val_loss: 12.9177 - val_mae: 2.4679 - val_mse: 12.9177\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4576 - mae: 1.9351 - mse: 7.4576 - val_loss: 12.7596 - val_mae: 2.4726 - val_mse: 12.7596\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4948 - mae: 1.9518 - mse: 7.4948 - val_loss: 12.6720 - val_mae: 2.4903 - val_mse: 12.6720\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4168 - mae: 1.9461 - mse: 7.4168 - val_loss: 12.3409 - val_mae: 2.4465 - val_mse: 12.3409\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4011 - mae: 1.9488 - mse: 7.4011 - val_loss: 12.4469 - val_mae: 2.4571 - val_mse: 12.4469\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3739 - mae: 1.9397 - mse: 7.3739 - val_loss: 12.6717 - val_mae: 2.4884 - val_mse: 12.6717\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3875 - mae: 1.9252 - mse: 7.3875 - val_loss: 12.6541 - val_mae: 2.4670 - val_mse: 12.6541\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3360 - mae: 1.9243 - mse: 7.3360 - val_loss: 12.6035 - val_mae: 2.4679 - val_mse: 12.6035\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3160 - mae: 1.9209 - mse: 7.3160 - val_loss: 12.5025 - val_mae: 2.4419 - val_mse: 12.5025\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2877 - mae: 1.9238 - mse: 7.2877 - val_loss: 12.4261 - val_mae: 2.4367 - val_mse: 12.4261\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1989 - mae: 1.9023 - mse: 7.1989 - val_loss: 12.6582 - val_mae: 2.4639 - val_mse: 12.6582\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2709 - mae: 1.9162 - mse: 7.2709 - val_loss: 12.3452 - val_mae: 2.4363 - val_mse: 12.3452\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1883 - mae: 1.9187 - mse: 7.1883 - val_loss: 12.1761 - val_mae: 2.4247 - val_mse: 12.1761\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1590 - mae: 1.9116 - mse: 7.1590 - val_loss: 12.4772 - val_mae: 2.4377 - val_mse: 12.4772\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2008 - mae: 1.8943 - mse: 7.2008 - val_loss: 12.5752 - val_mae: 2.4422 - val_mse: 12.5752\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0750 - mae: 1.8933 - mse: 7.0750 - val_loss: 12.4687 - val_mae: 2.4530 - val_mse: 12.4687\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3755 - mae: 1.9442 - mse: 7.3755 - val_loss: 12.3498 - val_mae: 2.4745 - val_mse: 12.3498\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0766 - mae: 1.9011 - mse: 7.0766 - val_loss: 12.3672 - val_mae: 2.4076 - val_mse: 12.3672\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0620 - mae: 1.8819 - mse: 7.0620 - val_loss: 12.3207 - val_mae: 2.4279 - val_mse: 12.3207\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0055 - mae: 1.8906 - mse: 7.0055 - val_loss: 12.2854 - val_mae: 2.4443 - val_mse: 12.2854\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9687 - mae: 1.8911 - mse: 6.9687 - val_loss: 12.3140 - val_mae: 2.4245 - val_mse: 12.3140\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0305 - mae: 1.8703 - mse: 7.0305 - val_loss: 12.4411 - val_mae: 2.4252 - val_mse: 12.4411\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9674 - mae: 1.8820 - mse: 6.9674 - val_loss: 12.3431 - val_mae: 2.4368 - val_mse: 12.3431\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0672 - mae: 1.9128 - mse: 7.0672 - val_loss: 11.9968 - val_mae: 2.3971 - val_mse: 11.9968\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8536 - mae: 1.8722 - mse: 6.8536 - val_loss: 12.4606 - val_mae: 2.4527 - val_mse: 12.4606\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9333 - mae: 1.8780 - mse: 6.9333 - val_loss: 12.3497 - val_mae: 2.4372 - val_mse: 12.3497\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9529 - mae: 1.8777 - mse: 6.9529 - val_loss: 12.1577 - val_mae: 2.3957 - val_mse: 12.1577\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9348 - mae: 1.8984 - mse: 6.9348 - val_loss: 12.1645 - val_mae: 2.4448 - val_mse: 12.1645\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8158 - mae: 1.8743 - mse: 6.8158 - val_loss: 12.0677 - val_mae: 2.4065 - val_mse: 12.0677\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8378 - mae: 1.8679 - mse: 6.8378 - val_loss: 11.9786 - val_mae: 2.3743 - val_mse: 11.9786\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7415 - mae: 1.8588 - mse: 6.7415 - val_loss: 11.8952 - val_mae: 2.3928 - val_mse: 11.8952\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7894 - mae: 1.8748 - mse: 6.7894 - val_loss: 12.0014 - val_mae: 2.4135 - val_mse: 12.0014\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6708 - mae: 1.8369 - mse: 6.6708 - val_loss: 12.1765 - val_mae: 2.3834 - val_mse: 12.1765\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7145 - mae: 1.8263 - mse: 6.7145 - val_loss: 11.9088 - val_mae: 2.3735 - val_mse: 11.9088\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6448 - mae: 1.8385 - mse: 6.6448 - val_loss: 12.0323 - val_mae: 2.4332 - val_mse: 12.0323\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6392 - mae: 1.8583 - mse: 6.6392 - val_loss: 11.7201 - val_mae: 2.3781 - val_mse: 11.7201\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5448 - mae: 1.8244 - mse: 6.5448 - val_loss: 11.9837 - val_mae: 2.3726 - val_mse: 11.9837\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6181 - mae: 1.8210 - mse: 6.6181 - val_loss: 12.1897 - val_mae: 2.4132 - val_mse: 12.1897\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5788 - mae: 1.8378 - mse: 6.5788 - val_loss: 11.8153 - val_mae: 2.4121 - val_mse: 11.8153\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5338 - mae: 1.8311 - mse: 6.5338 - val_loss: 12.0468 - val_mae: 2.3960 - val_mse: 12.0468\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5303 - mae: 1.8097 - mse: 6.5303 - val_loss: 11.8029 - val_mae: 2.3826 - val_mse: 11.8029\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4552 - mae: 1.8223 - mse: 6.4552 - val_loss: 11.7844 - val_mae: 2.3965 - val_mse: 11.7844\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4227 - mae: 1.8120 - mse: 6.4227 - val_loss: 11.7370 - val_mae: 2.3604 - val_mse: 11.7370\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4223 - mae: 1.8245 - mse: 6.4223 - val_loss: 11.6650 - val_mae: 2.3533 - val_mse: 11.6650\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3883 - mae: 1.7953 - mse: 6.3883 - val_loss: 11.9791 - val_mae: 2.3710 - val_mse: 11.9791\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3310 - mae: 1.7940 - mse: 6.3310 - val_loss: 12.0199 - val_mae: 2.4095 - val_mse: 12.0199\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3989 - mae: 1.8211 - mse: 6.3989 - val_loss: 11.5018 - val_mae: 2.3434 - val_mse: 11.5018\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4286 - mae: 1.8007 - mse: 6.4286 - val_loss: 11.8953 - val_mae: 2.3627 - val_mse: 11.8953\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1950 - mae: 1.7709 - mse: 6.1950 - val_loss: 11.6055 - val_mae: 2.3737 - val_mse: 11.6055\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2956 - mae: 1.8049 - mse: 6.2956 - val_loss: 11.8996 - val_mae: 2.4017 - val_mse: 11.8996\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2114 - mae: 1.7844 - mse: 6.2114 - val_loss: 11.7038 - val_mae: 2.3667 - val_mse: 11.7038\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3136 - mae: 1.8113 - mse: 6.3136 - val_loss: 11.4601 - val_mae: 2.3475 - val_mse: 11.4601\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2173 - mae: 1.7839 - mse: 6.2173 - val_loss: 11.8160 - val_mae: 2.3512 - val_mse: 11.8160\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1547 - mae: 1.7762 - mse: 6.1547 - val_loss: 11.7151 - val_mae: 2.3731 - val_mse: 11.7151\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2082 - mae: 1.7934 - mse: 6.2082 - val_loss: 11.8348 - val_mae: 2.3930 - val_mse: 11.8348\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0807 - mae: 1.7765 - mse: 6.0807 - val_loss: 11.3906 - val_mae: 2.3249 - val_mse: 11.3906\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1330 - mae: 1.7781 - mse: 6.1330 - val_loss: 11.4922 - val_mae: 2.3451 - val_mse: 11.4922\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0840 - mae: 1.7913 - mse: 6.0840 - val_loss: 11.6169 - val_mae: 2.3651 - val_mse: 11.6169\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0693 - mae: 1.7636 - mse: 6.0693 - val_loss: 11.8724 - val_mae: 2.3673 - val_mse: 11.8724\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9735 - mae: 1.7519 - mse: 5.9735 - val_loss: 11.6726 - val_mae: 2.3809 - val_mse: 11.6726\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0440 - mae: 1.7835 - mse: 6.0440 - val_loss: 11.4426 - val_mae: 2.3559 - val_mse: 11.4426\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9560 - mae: 1.7567 - mse: 5.9560 - val_loss: 11.4687 - val_mae: 2.3127 - val_mse: 11.4687\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9559 - mae: 1.7504 - mse: 5.9559 - val_loss: 11.2267 - val_mae: 2.3142 - val_mse: 11.2267\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9499 - mae: 1.7686 - mse: 5.9499 - val_loss: 11.3857 - val_mae: 2.3378 - val_mse: 11.3857\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8753 - mae: 1.7499 - mse: 5.8753 - val_loss: 11.5834 - val_mae: 2.3456 - val_mse: 11.5834\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8433 - mae: 1.7378 - mse: 5.8433 - val_loss: 11.5309 - val_mae: 2.3461 - val_mse: 11.5309\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7830 - mae: 1.7297 - mse: 5.7830 - val_loss: 11.5999 - val_mae: 2.3589 - val_mse: 11.5999\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8040 - mae: 1.7297 - mse: 5.8040 - val_loss: 11.2998 - val_mae: 2.3228 - val_mse: 11.2998\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8166 - mae: 1.7296 - mse: 5.8166 - val_loss: 11.5173 - val_mae: 2.3424 - val_mse: 11.5173\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7240 - mae: 1.7157 - mse: 5.7240 - val_loss: 11.3844 - val_mae: 2.3362 - val_mse: 11.3844\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7172 - mae: 1.7178 - mse: 5.7172 - val_loss: 11.3403 - val_mae: 2.3224 - val_mse: 11.3403\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6919 - mae: 1.7068 - mse: 5.6919 - val_loss: 11.5716 - val_mae: 2.3510 - val_mse: 11.5716\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6679 - mae: 1.7047 - mse: 5.6679 - val_loss: 11.4641 - val_mae: 2.3372 - val_mse: 11.4641\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7998 - mae: 1.7481 - mse: 5.7998 - val_loss: 11.1771 - val_mae: 2.3203 - val_mse: 11.1771\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6999 - mae: 1.7163 - mse: 5.6999 - val_loss: 11.3365 - val_mae: 2.3179 - val_mse: 11.3365\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6702 - mae: 1.7052 - mse: 5.6702 - val_loss: 11.1789 - val_mae: 2.3156 - val_mse: 11.1789\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5908 - mae: 1.7025 - mse: 5.5908 - val_loss: 11.3842 - val_mae: 2.3166 - val_mse: 11.3842\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5629 - mae: 1.6997 - mse: 5.5629 - val_loss: 11.7297 - val_mae: 2.3854 - val_mse: 11.7297\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5557 - mae: 1.6949 - mse: 5.5557 - val_loss: 11.4967 - val_mae: 2.3234 - val_mse: 11.4967\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4732 - mae: 1.6800 - mse: 5.4732 - val_loss: 11.3255 - val_mae: 2.3235 - val_mse: 11.3255\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5369 - mae: 1.6916 - mse: 5.5369 - val_loss: 11.1036 - val_mae: 2.3037 - val_mse: 11.1036\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4618 - mae: 1.6739 - mse: 5.4618 - val_loss: 11.1296 - val_mae: 2.2862 - val_mse: 11.1296\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4056 - mae: 1.6663 - mse: 5.4056 - val_loss: 11.2313 - val_mae: 2.3076 - val_mse: 11.2313\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4400 - mae: 1.6790 - mse: 5.4400 - val_loss: 11.5175 - val_mae: 2.3443 - val_mse: 11.5175\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4071 - mae: 1.6607 - mse: 5.4071 - val_loss: 11.0672 - val_mae: 2.2879 - val_mse: 11.0672\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4075 - mae: 1.6732 - mse: 5.4075 - val_loss: 11.2469 - val_mae: 2.3149 - val_mse: 11.2469\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3655 - mae: 1.6640 - mse: 5.3655 - val_loss: 11.1086 - val_mae: 2.2813 - val_mse: 11.1086\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3419 - mae: 1.6606 - mse: 5.3419 - val_loss: 11.2808 - val_mae: 2.3142 - val_mse: 11.2808\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3300 - mae: 1.6639 - mse: 5.3300 - val_loss: 11.2153 - val_mae: 2.3231 - val_mse: 11.2153\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2562 - mae: 1.6512 - mse: 5.2562 - val_loss: 11.5402 - val_mae: 2.3380 - val_mse: 11.5402\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2984 - mae: 1.6413 - mse: 5.2984 - val_loss: 11.1449 - val_mae: 2.2879 - val_mse: 11.1449\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3053 - mae: 1.6699 - mse: 5.3053 - val_loss: 11.0342 - val_mae: 2.3094 - val_mse: 11.0342\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2679 - mae: 1.6533 - mse: 5.2679 - val_loss: 11.1405 - val_mae: 2.2946 - val_mse: 11.1405\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2481 - mae: 1.6496 - mse: 5.2481 - val_loss: 10.9457 - val_mae: 2.2778 - val_mse: 10.9457\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2358 - mae: 1.6434 - mse: 5.2358 - val_loss: 11.0034 - val_mae: 2.2724 - val_mse: 11.0034\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1229 - mae: 1.6236 - mse: 5.1229 - val_loss: 11.2402 - val_mae: 2.3176 - val_mse: 11.2402\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0989 - mae: 1.6291 - mse: 5.0989 - val_loss: 10.8990 - val_mae: 2.2499 - val_mse: 10.8990\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1224 - mae: 1.6296 - mse: 5.1224 - val_loss: 11.3130 - val_mae: 2.3141 - val_mse: 11.3130\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0908 - mae: 1.6340 - mse: 5.0908 - val_loss: 10.9794 - val_mae: 2.2715 - val_mse: 10.9794\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0534 - mae: 1.6211 - mse: 5.0534 - val_loss: 10.8573 - val_mae: 2.2634 - val_mse: 10.8573\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0262 - mae: 1.6218 - mse: 5.0262 - val_loss: 10.8857 - val_mae: 2.2655 - val_mse: 10.8857\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0159 - mae: 1.6153 - mse: 5.0159 - val_loss: 11.2075 - val_mae: 2.2999 - val_mse: 11.2075\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0372 - mae: 1.6081 - mse: 5.0372 - val_loss: 10.8928 - val_mae: 2.2545 - val_mse: 10.8928\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9454 - mae: 1.6112 - mse: 4.9454 - val_loss: 11.1291 - val_mae: 2.3248 - val_mse: 11.1291\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1102 - mae: 1.6462 - mse: 5.1102 - val_loss: 10.7812 - val_mae: 2.2532 - val_mse: 10.7812\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0086 - mae: 1.6072 - mse: 5.0086 - val_loss: 11.1156 - val_mae: 2.2788 - val_mse: 11.1156\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9624 - mae: 1.6058 - mse: 4.9624 - val_loss: 10.9469 - val_mae: 2.2890 - val_mse: 10.9469\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8864 - mae: 1.6048 - mse: 4.8864 - val_loss: 10.9825 - val_mae: 2.2772 - val_mse: 10.9825\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9444 - mae: 1.5891 - mse: 4.9444 - val_loss: 11.0006 - val_mae: 2.2724 - val_mse: 11.0006\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9407 - mae: 1.5919 - mse: 4.9407 - val_loss: 10.6494 - val_mae: 2.2756 - val_mse: 10.6494\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8403 - mae: 1.5992 - mse: 4.8403 - val_loss: 10.7533 - val_mae: 2.2541 - val_mse: 10.7533\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8261 - mae: 1.5753 - mse: 4.8261 - val_loss: 10.9119 - val_mae: 2.2725 - val_mse: 10.9119\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7230 - mae: 1.5600 - mse: 4.7230 - val_loss: 10.6384 - val_mae: 2.2560 - val_mse: 10.6384\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7422 - mae: 1.5795 - mse: 4.7422 - val_loss: 10.9263 - val_mae: 2.2868 - val_mse: 10.9263\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7826 - mae: 1.5548 - mse: 4.7826 - val_loss: 11.0119 - val_mae: 2.2733 - val_mse: 11.0119\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6616 - mae: 1.5482 - mse: 4.6616 - val_loss: 10.8180 - val_mae: 2.2986 - val_mse: 10.8180\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7684 - mae: 1.5831 - mse: 4.7684 - val_loss: 10.6285 - val_mae: 2.2225 - val_mse: 10.6285\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6470 - mae: 1.5513 - mse: 4.6470 - val_loss: 11.1563 - val_mae: 2.3025 - val_mse: 11.1563\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6933 - mae: 1.5724 - mse: 4.6933 - val_loss: 10.9393 - val_mae: 2.2770 - val_mse: 10.9393\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7289 - mae: 1.5663 - mse: 4.7289 - val_loss: 10.8070 - val_mae: 2.2367 - val_mse: 10.8070\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5879 - mae: 1.5464 - mse: 4.5879 - val_loss: 11.2571 - val_mae: 2.3436 - val_mse: 11.2571\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5105 - mae: 1.5407 - mse: 4.5105 - val_loss: 10.4132 - val_mae: 2.1950 - val_mse: 10.4132\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6814 - mae: 1.5482 - mse: 4.6814 - val_loss: 11.0737 - val_mae: 2.2679 - val_mse: 11.0737\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 4.6860 - mae: 1.5799 - mse: 4.6860 - val_loss: 11.2348 - val_mae: 2.3261 - val_mse: 11.2348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQJJD8zJvDv5",
        "colab_type": "text"
      },
      "source": [
        "모델 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLWZGdgXvR9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7b10bfeb-d136-470a-dc0c-e7172a870ac0"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4272 - mae: 2.1745 - mse: 9.4272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.427238464355469, 2.174511432647705, 9.427238464355469]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYZiu51hvjj5",
        "colab_type": "text"
      },
      "source": [
        "모델 결과 그리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHZf8SHdvop8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6bbc0bb9-17d1-4de1-b08e-410aa8097406"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "his_dict = history.history\n",
        "mse = his_dict['mse']\n",
        "val_mse = his_dict['val_mse'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
        "\n",
        "epochs = range(1, len(mse) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# 훈련 및 검증 손실 그리기\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, mse, color = 'blue', label = 'train_mse')\n",
        "ax1.plot(epochs, val_mse, color = 'orange', label = 'val_mse')\n",
        "ax1.set_title('train and val mse')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('mse')\n",
        "ax1.legend()\n",
        "\n",
        "mae = his_dict['mae']\n",
        "val_mae = his_dict['val_mae']\n",
        "\n",
        "# 훈련 및 검증 정확도 그리기\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, mae, color = 'blue', label = 'train_mae')\n",
        "ax2.plot(epochs, val_mae, color = 'orange', label = 'val_mae')\n",
        "ax2.set_title('train and val mae')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 2200달러 정도 차이남"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmybUrUv89S",
        "colab_type": "text"
      },
      "source": [
        "모델 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5CfQpw-wHa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "886ed404-f723-4b3a-d8d3-12870e965eb8"
      },
      "source": [
        "# 스케터 좌표\n",
        "\n",
        "test_predictions = model.predict(x_val).flatten()\n",
        "\n",
        "plt.scatter(y_val, test_predictions)\n",
        "plt.xlabel('True Values [Price]')\n",
        "plt.ylabel('Predictions [Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "\n",
        "# 가운데에 잘 붙어야지 예측 잘 된"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGNXTB7cwxaj",
        "colab_type": "text"
      },
      "source": [
        "K-Fold 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCjMvARiw7PS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e4fde78-9347-4296-9448-210adbdab29d"
      },
      "source": [
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                 test_split=0.2,\n",
        "                                                 seed=777)\n",
        "\n",
        "# 데이터 표준화\n",
        "mean = np.mean(x_train, axis = 0)\n",
        "std = np.std(x_train, axis = 0)\n",
        "# 여기까진 전부 동일합니다.\n",
        "x_train = (x_train - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "\n",
        "#----------------------------------------\n",
        "# K-Fold를 진행해봅니다.\n",
        "k = 3\n",
        "\n",
        "# 주어진 데이터셋을 k만큼 등분합니다.\n",
        "# 여기서는 3이므로 훈련 데이터셋(404개)를 3등분하여\n",
        "# 1개는 검증셋으로, 나머지 2개는 훈련셋으로 활용합니다.\n",
        "kfold = KFold(n_splits=k, random_state = 777)\n",
        "\n",
        "# 재사용을 위해 모델을 반환하는 함수를 정의합니다.\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation = 'relu', input_shape = (13, )))\n",
        "    model.add(Dense(32, activation = 'relu')) \n",
        "    model.add(Dense(1))   \n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "mae_list = [] # 테스트셋을 평가한 후 결과 mae를 담을 리스트를 선언합니다.\n",
        "\n",
        "# k번 진행합니다.\n",
        "for train_index, val_index in kfold.split(x_train):\n",
        "    # 해당 인덱스는 무작위로 생성됩니다.\n",
        "    # 무작위로 생성해주는 것은 과대적합을 피할 수 있는 좋은 방법입니다.\n",
        "    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "    \n",
        "    # 모델을 불러옵니다.\n",
        "    model = get_model()\n",
        "    \n",
        "    model.fit(x_train_fold, y_train_fold, epochs = 300, validation_data = (x_val_fold, y_val_fold))\n",
        "    \n",
        "    _, test_mae = model.evaluate(x_test, y_test)\n",
        "    mae_list.append(test_mae)\n",
        "\n",
        "# 3번을 나눠서 학습시킴"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 549.4238 - mae: 21.5559 - val_loss: 520.2543 - val_mae: 20.9673\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 516.2484 - mae: 20.8065 - val_loss: 485.9295 - val_mae: 20.1710\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 476.8007 - mae: 19.8943 - val_loss: 444.4507 - val_mae: 19.1595\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 429.9081 - mae: 18.7395 - val_loss: 394.0013 - val_mae: 17.8693\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 374.4933 - mae: 17.2788 - val_loss: 335.4031 - val_mae: 16.2696\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 311.2788 - mae: 15.4862 - val_loss: 270.7544 - val_mae: 14.3082\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 243.3772 - mae: 13.4429 - val_loss: 205.6039 - val_mae: 12.0250\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 180.0605 - mae: 11.2020 - val_loss: 146.0727 - val_mae: 9.7059\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 127.6183 - mae: 8.9450 - val_loss: 102.6613 - val_mae: 7.8388\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 95.0470 - mae: 7.4539 - val_loss: 75.4371 - val_mae: 6.5800\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 75.9985 - mae: 6.5900 - val_loss: 60.0696 - val_mae: 5.7559\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 64.1610 - mae: 6.0331 - val_loss: 50.1959 - val_mae: 5.1488\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 54.7139 - mae: 5.5630 - val_loss: 43.3115 - val_mae: 4.7180\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 46.9968 - mae: 5.1111 - val_loss: 38.4570 - val_mae: 4.4457\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 41.6583 - mae: 4.7393 - val_loss: 34.7315 - val_mae: 4.2177\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 37.3521 - mae: 4.4345 - val_loss: 32.0473 - val_mae: 4.0611\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 34.3607 - mae: 4.2360 - val_loss: 30.0397 - val_mae: 3.9628\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31.7439 - mae: 4.0492 - val_loss: 28.5322 - val_mae: 3.8721\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29.9805 - mae: 3.9257 - val_loss: 27.3168 - val_mae: 3.8175\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 28.3628 - mae: 3.8261 - val_loss: 26.4334 - val_mae: 3.7651\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 27.0608 - mae: 3.7140 - val_loss: 25.7806 - val_mae: 3.7116\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 26.0239 - mae: 3.6282 - val_loss: 25.1300 - val_mae: 3.6717\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.9988 - mae: 3.5520 - val_loss: 24.5943 - val_mae: 3.6346\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.0370 - mae: 3.4650 - val_loss: 24.1929 - val_mae: 3.5950\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 23.3213 - mae: 3.3833 - val_loss: 23.9008 - val_mae: 3.5548\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.5660 - mae: 3.3123 - val_loss: 23.4503 - val_mae: 3.5286\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.8522 - mae: 3.2649 - val_loss: 23.0415 - val_mae: 3.4994\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.2776 - mae: 3.2262 - val_loss: 22.7166 - val_mae: 3.4789\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.6550 - mae: 3.1662 - val_loss: 22.3961 - val_mae: 3.4586\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.0607 - mae: 3.1200 - val_loss: 22.1246 - val_mae: 3.4421\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.6583 - mae: 3.0885 - val_loss: 21.7957 - val_mae: 3.4247\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.0715 - mae: 3.0433 - val_loss: 21.5473 - val_mae: 3.4094\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.6429 - mae: 2.9929 - val_loss: 21.4145 - val_mae: 3.3958\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.2611 - mae: 2.9697 - val_loss: 21.0965 - val_mae: 3.3901\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.7585 - mae: 2.9346 - val_loss: 20.8192 - val_mae: 3.3709\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.3588 - mae: 2.8899 - val_loss: 20.6246 - val_mae: 3.3488\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.0759 - mae: 2.8536 - val_loss: 20.5043 - val_mae: 3.3373\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.7154 - mae: 2.8183 - val_loss: 20.2009 - val_mae: 3.3109\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.3478 - mae: 2.7867 - val_loss: 19.9587 - val_mae: 3.2986\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.1679 - mae: 2.7956 - val_loss: 19.7120 - val_mae: 3.2930\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.7429 - mae: 2.7503 - val_loss: 19.5959 - val_mae: 3.2693\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.5712 - mae: 2.7210 - val_loss: 19.3772 - val_mae: 3.2534\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.4426 - mae: 2.7308 - val_loss: 19.2212 - val_mae: 3.2623\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.0562 - mae: 2.7010 - val_loss: 18.9760 - val_mae: 3.2317\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8082 - mae: 2.6741 - val_loss: 18.8342 - val_mae: 3.2237\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.6085 - mae: 2.6609 - val_loss: 18.6845 - val_mae: 3.2175\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.3964 - mae: 2.6430 - val_loss: 18.5879 - val_mae: 3.2059\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.1995 - mae: 2.6129 - val_loss: 18.5545 - val_mae: 3.2035\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.9661 - mae: 2.5924 - val_loss: 18.4034 - val_mae: 3.2018\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7822 - mae: 2.5848 - val_loss: 18.2344 - val_mae: 3.1937\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.6612 - mae: 2.5798 - val_loss: 18.1555 - val_mae: 3.1824\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.5658 - mae: 2.5667 - val_loss: 18.0694 - val_mae: 3.1849\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.3255 - mae: 2.5429 - val_loss: 18.0157 - val_mae: 3.1730\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.1983 - mae: 2.5275 - val_loss: 17.9030 - val_mae: 3.1542\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.0602 - mae: 2.5070 - val_loss: 17.6007 - val_mae: 3.1161\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.9874 - mae: 2.5169 - val_loss: 17.3378 - val_mae: 3.1077\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.7270 - mae: 2.5061 - val_loss: 17.2913 - val_mae: 3.1060\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6049 - mae: 2.4868 - val_loss: 17.2598 - val_mae: 3.0953\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4556 - mae: 2.4594 - val_loss: 17.1341 - val_mae: 3.0786\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.4116 - mae: 2.4550 - val_loss: 17.0114 - val_mae: 3.0616\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.2904 - mae: 2.4566 - val_loss: 16.8289 - val_mae: 3.0652\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1463 - mae: 2.4596 - val_loss: 16.7510 - val_mae: 3.0522\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.9925 - mae: 2.4389 - val_loss: 16.7156 - val_mae: 3.0456\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.9362 - mae: 2.4331 - val_loss: 16.6098 - val_mae: 3.0369\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.7285 - mae: 2.4041 - val_loss: 16.5795 - val_mae: 3.0258\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7349 - mae: 2.3971 - val_loss: 16.5506 - val_mae: 3.0132\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5474 - mae: 2.3945 - val_loss: 16.3371 - val_mae: 3.0104\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5378 - mae: 2.4062 - val_loss: 16.3485 - val_mae: 3.0253\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3819 - mae: 2.3818 - val_loss: 16.2561 - val_mae: 3.0040\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3226 - mae: 2.3773 - val_loss: 16.2974 - val_mae: 3.0149\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1523 - mae: 2.3591 - val_loss: 16.2410 - val_mae: 2.9895\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1218 - mae: 2.3572 - val_loss: 16.0868 - val_mae: 2.9666\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1224 - mae: 2.3554 - val_loss: 16.0964 - val_mae: 2.9649\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3777 - mae: 2.3933 - val_loss: 15.9300 - val_mae: 2.9779\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.0577 - mae: 2.3597 - val_loss: 15.9167 - val_mae: 2.9343\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8240 - mae: 2.3362 - val_loss: 15.7032 - val_mae: 2.9272\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7233 - mae: 2.3465 - val_loss: 15.5944 - val_mae: 2.9284\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6637 - mae: 2.3363 - val_loss: 15.6994 - val_mae: 2.9315\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5533 - mae: 2.3259 - val_loss: 15.7164 - val_mae: 2.9396\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4620 - mae: 2.3219 - val_loss: 15.6325 - val_mae: 2.9408\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3649 - mae: 2.3101 - val_loss: 15.5852 - val_mae: 2.9395\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3140 - mae: 2.2980 - val_loss: 15.4544 - val_mae: 2.9160\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.2360 - mae: 2.2931 - val_loss: 15.3642 - val_mae: 2.9220\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.1913 - mae: 2.2874 - val_loss: 15.4062 - val_mae: 2.9255\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0858 - mae: 2.2736 - val_loss: 15.3534 - val_mae: 2.9109\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0445 - mae: 2.2704 - val_loss: 15.3429 - val_mae: 2.9130\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9973 - mae: 2.2677 - val_loss: 15.3650 - val_mae: 2.9112\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9852 - mae: 2.2640 - val_loss: 15.2343 - val_mae: 2.9019\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8616 - mae: 2.2631 - val_loss: 15.3281 - val_mae: 2.9164\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8187 - mae: 2.2565 - val_loss: 15.1213 - val_mae: 2.8797\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.7281 - mae: 2.2450 - val_loss: 15.0297 - val_mae: 2.8641\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6785 - mae: 2.2376 - val_loss: 15.0127 - val_mae: 2.8627\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.6067 - mae: 2.2338 - val_loss: 14.9442 - val_mae: 2.8531\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5723 - mae: 2.2322 - val_loss: 14.9564 - val_mae: 2.8601\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4976 - mae: 2.2227 - val_loss: 14.8241 - val_mae: 2.8476\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4996 - mae: 2.2220 - val_loss: 14.8040 - val_mae: 2.8439\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3972 - mae: 2.2123 - val_loss: 14.8762 - val_mae: 2.8573\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3416 - mae: 2.2080 - val_loss: 14.8594 - val_mae: 2.8687\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3221 - mae: 2.2109 - val_loss: 14.8107 - val_mae: 2.8492\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2701 - mae: 2.1960 - val_loss: 14.7909 - val_mae: 2.8263\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1932 - mae: 2.1937 - val_loss: 14.6939 - val_mae: 2.8177\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1841 - mae: 2.1889 - val_loss: 14.5931 - val_mae: 2.8231\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1495 - mae: 2.1946 - val_loss: 14.5771 - val_mae: 2.8203\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0156 - mae: 2.1698 - val_loss: 14.6573 - val_mae: 2.8260\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0794 - mae: 2.1816 - val_loss: 14.7225 - val_mae: 2.8258\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9331 - mae: 2.1685 - val_loss: 14.3963 - val_mae: 2.7963\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9959 - mae: 2.1692 - val_loss: 14.4809 - val_mae: 2.8236\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9371 - mae: 2.1566 - val_loss: 14.6174 - val_mae: 2.8305\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7927 - mae: 2.1535 - val_loss: 14.4626 - val_mae: 2.8254\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9164 - mae: 2.1679 - val_loss: 14.4859 - val_mae: 2.8429\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7548 - mae: 2.1590 - val_loss: 14.5097 - val_mae: 2.8342\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.6791 - mae: 2.1406 - val_loss: 14.5414 - val_mae: 2.8236\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5991 - mae: 2.1334 - val_loss: 14.4461 - val_mae: 2.8212\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6234 - mae: 2.1417 - val_loss: 14.4244 - val_mae: 2.8274\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5527 - mae: 2.1221 - val_loss: 14.4945 - val_mae: 2.8181\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4825 - mae: 2.1222 - val_loss: 14.3816 - val_mae: 2.8080\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4325 - mae: 2.1096 - val_loss: 14.3792 - val_mae: 2.8257\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3868 - mae: 2.1105 - val_loss: 14.3345 - val_mae: 2.8173\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3595 - mae: 2.1025 - val_loss: 14.2462 - val_mae: 2.8007\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3151 - mae: 2.0939 - val_loss: 14.3359 - val_mae: 2.8186\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3103 - mae: 2.1007 - val_loss: 14.1439 - val_mae: 2.7948\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2429 - mae: 2.0900 - val_loss: 14.2155 - val_mae: 2.8102\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1827 - mae: 2.0792 - val_loss: 14.1959 - val_mae: 2.8060\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1147 - mae: 2.0707 - val_loss: 14.2150 - val_mae: 2.8022\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1261 - mae: 2.0719 - val_loss: 14.2023 - val_mae: 2.8012\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0168 - mae: 2.0617 - val_loss: 14.0477 - val_mae: 2.7760\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9693 - mae: 2.0545 - val_loss: 14.0082 - val_mae: 2.7768\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9680 - mae: 2.0569 - val_loss: 13.9863 - val_mae: 2.7793\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9392 - mae: 2.0509 - val_loss: 13.9708 - val_mae: 2.7708\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9195 - mae: 2.0539 - val_loss: 13.9903 - val_mae: 2.7536\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8789 - mae: 2.0442 - val_loss: 14.0232 - val_mae: 2.7776\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8248 - mae: 2.0366 - val_loss: 13.9119 - val_mae: 2.7723\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8032 - mae: 2.0416 - val_loss: 13.7428 - val_mae: 2.7413\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8154 - mae: 2.0354 - val_loss: 14.0422 - val_mae: 2.7907\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7612 - mae: 2.0335 - val_loss: 13.9922 - val_mae: 2.7886\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6845 - mae: 2.0040 - val_loss: 13.9816 - val_mae: 2.7728\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5826 - mae: 2.0053 - val_loss: 13.9929 - val_mae: 2.7860\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5544 - mae: 2.0066 - val_loss: 13.8703 - val_mae: 2.7716\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4779 - mae: 1.9961 - val_loss: 13.7258 - val_mae: 2.7438\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5061 - mae: 1.9957 - val_loss: 13.8766 - val_mae: 2.7716\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4580 - mae: 1.9921 - val_loss: 13.6452 - val_mae: 2.7429\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4489 - mae: 1.9979 - val_loss: 13.6028 - val_mae: 2.7387\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3636 - mae: 1.9747 - val_loss: 13.7002 - val_mae: 2.7484\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2925 - mae: 1.9633 - val_loss: 13.6916 - val_mae: 2.7412\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3234 - mae: 1.9679 - val_loss: 13.6090 - val_mae: 2.7316\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2203 - mae: 1.9613 - val_loss: 13.7138 - val_mae: 2.7569\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2057 - mae: 1.9528 - val_loss: 13.5538 - val_mae: 2.7269\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1484 - mae: 1.9405 - val_loss: 13.6039 - val_mae: 2.7389\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 1.9457 - val_loss: 13.6660 - val_mae: 2.7565\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1328 - mae: 1.9474 - val_loss: 13.6022 - val_mae: 2.7464\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1999 - mae: 1.9463 - val_loss: 13.5726 - val_mae: 2.7284\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3069 - mae: 1.9695 - val_loss: 13.6064 - val_mae: 2.7431\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9853 - mae: 1.9219 - val_loss: 13.5228 - val_mae: 2.7296\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9917 - mae: 1.9245 - val_loss: 13.7397 - val_mae: 2.7635\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9423 - mae: 1.9204 - val_loss: 13.5886 - val_mae: 2.7398\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8726 - mae: 1.9024 - val_loss: 13.5780 - val_mae: 2.7372\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7978 - mae: 1.9039 - val_loss: 13.5395 - val_mae: 2.7344\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8707 - mae: 1.9065 - val_loss: 13.5760 - val_mae: 2.7445\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7384 - mae: 1.8848 - val_loss: 13.6035 - val_mae: 2.7314\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7236 - mae: 1.8851 - val_loss: 13.4215 - val_mae: 2.7121\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7250 - mae: 1.8953 - val_loss: 13.4230 - val_mae: 2.7158\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7158 - mae: 1.8864 - val_loss: 13.3398 - val_mae: 2.7028\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5927 - mae: 1.8699 - val_loss: 13.5730 - val_mae: 2.7456\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5275 - mae: 1.8618 - val_loss: 13.3967 - val_mae: 2.7090\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5015 - mae: 1.8554 - val_loss: 13.3260 - val_mae: 2.6937\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4499 - mae: 1.8519 - val_loss: 13.3856 - val_mae: 2.7069\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4700 - mae: 1.8529 - val_loss: 13.3561 - val_mae: 2.7049\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4332 - mae: 1.8480 - val_loss: 13.3058 - val_mae: 2.6974\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4022 - mae: 1.8441 - val_loss: 13.2437 - val_mae: 2.6859\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3212 - mae: 1.8279 - val_loss: 13.1686 - val_mae: 2.6625\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3902 - mae: 1.8414 - val_loss: 13.2515 - val_mae: 2.6831\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2503 - mae: 1.8193 - val_loss: 13.1314 - val_mae: 2.6594\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2605 - mae: 1.8215 - val_loss: 13.1027 - val_mae: 2.6541\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2094 - mae: 1.8110 - val_loss: 13.1196 - val_mae: 2.6545\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1874 - mae: 1.8086 - val_loss: 13.2031 - val_mae: 2.6731\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1231 - mae: 1.7967 - val_loss: 13.2344 - val_mae: 2.6692\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1184 - mae: 1.8092 - val_loss: 13.3403 - val_mae: 2.6916\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0801 - mae: 1.8004 - val_loss: 13.0788 - val_mae: 2.6426\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0812 - mae: 1.7873 - val_loss: 13.0981 - val_mae: 2.6457\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9993 - mae: 1.7910 - val_loss: 13.2450 - val_mae: 2.6807\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0158 - mae: 1.7947 - val_loss: 13.0792 - val_mae: 2.6502\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9989 - mae: 1.7862 - val_loss: 13.0887 - val_mae: 2.6562\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9181 - mae: 1.7591 - val_loss: 13.1826 - val_mae: 2.6665\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9219 - mae: 1.7580 - val_loss: 13.0929 - val_mae: 2.6531\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8447 - mae: 1.7554 - val_loss: 13.0924 - val_mae: 2.6603\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8563 - mae: 1.7653 - val_loss: 13.0402 - val_mae: 2.6470\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7954 - mae: 1.7514 - val_loss: 13.0464 - val_mae: 2.6406\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8071 - mae: 1.7431 - val_loss: 12.9585 - val_mae: 2.6271\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7323 - mae: 1.7481 - val_loss: 13.1897 - val_mae: 2.6723\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7670 - mae: 1.7520 - val_loss: 13.0490 - val_mae: 2.6456\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6477 - mae: 1.7210 - val_loss: 13.0920 - val_mae: 2.6504\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7182 - mae: 1.7337 - val_loss: 12.8954 - val_mae: 2.6110\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6471 - mae: 1.7363 - val_loss: 13.2269 - val_mae: 2.6626\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5973 - mae: 1.7425 - val_loss: 12.9833 - val_mae: 2.6210\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6094 - mae: 1.7137 - val_loss: 12.9814 - val_mae: 2.6202\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6270 - mae: 1.7283 - val_loss: 13.0148 - val_mae: 2.6283\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4599 - mae: 1.6947 - val_loss: 13.0306 - val_mae: 2.6348\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4610 - mae: 1.7017 - val_loss: 12.8934 - val_mae: 2.6073\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4482 - mae: 1.6987 - val_loss: 12.9409 - val_mae: 2.6177\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4918 - mae: 1.7121 - val_loss: 13.0244 - val_mae: 2.6377\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3692 - mae: 1.6798 - val_loss: 13.0673 - val_mae: 2.6376\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3904 - mae: 1.6864 - val_loss: 12.8974 - val_mae: 2.6010\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3313 - mae: 1.6823 - val_loss: 12.9044 - val_mae: 2.6068\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3043 - mae: 1.6799 - val_loss: 12.9602 - val_mae: 2.6185\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2851 - mae: 1.6909 - val_loss: 13.1120 - val_mae: 2.6435\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2783 - mae: 1.6779 - val_loss: 12.9825 - val_mae: 2.6240\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2274 - mae: 1.6632 - val_loss: 12.9378 - val_mae: 2.6133\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2360 - mae: 1.6655 - val_loss: 13.0190 - val_mae: 2.6319\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1884 - mae: 1.6417 - val_loss: 12.8429 - val_mae: 2.5999\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1848 - mae: 1.6700 - val_loss: 12.9898 - val_mae: 2.6251\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1079 - mae: 1.6550 - val_loss: 13.0469 - val_mae: 2.6387\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1331 - mae: 1.6422 - val_loss: 12.9235 - val_mae: 2.6137\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1182 - mae: 1.6348 - val_loss: 12.7229 - val_mae: 2.5751\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1053 - mae: 1.6423 - val_loss: 12.8239 - val_mae: 2.5898\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9905 - mae: 1.6291 - val_loss: 12.7579 - val_mae: 2.5821\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0143 - mae: 1.6372 - val_loss: 12.8000 - val_mae: 2.5947\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0388 - mae: 1.6359 - val_loss: 12.7319 - val_mae: 2.5835\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9515 - mae: 1.6180 - val_loss: 12.7752 - val_mae: 2.5841\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9531 - mae: 1.6365 - val_loss: 12.7805 - val_mae: 2.5858\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9717 - mae: 1.6281 - val_loss: 12.9069 - val_mae: 2.6109\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9534 - mae: 1.6309 - val_loss: 12.8509 - val_mae: 2.5948\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8871 - mae: 1.6212 - val_loss: 12.8742 - val_mae: 2.6023\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8277 - mae: 1.6004 - val_loss: 12.8769 - val_mae: 2.6039\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8432 - mae: 1.6032 - val_loss: 12.7724 - val_mae: 2.5904\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7482 - mae: 1.5935 - val_loss: 12.8891 - val_mae: 2.6045\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7822 - mae: 1.6076 - val_loss: 12.8454 - val_mae: 2.5898\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7333 - mae: 1.5854 - val_loss: 12.6354 - val_mae: 2.5611\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7702 - mae: 1.5863 - val_loss: 12.8132 - val_mae: 2.5891\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8538 - mae: 1.6272 - val_loss: 13.0778 - val_mae: 2.6331\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7436 - mae: 1.6020 - val_loss: 12.8572 - val_mae: 2.6018\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6822 - mae: 1.5824 - val_loss: 13.0328 - val_mae: 2.6209\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7192 - mae: 1.5885 - val_loss: 12.9879 - val_mae: 2.6025\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6373 - mae: 1.5742 - val_loss: 13.0638 - val_mae: 2.6157\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6787 - mae: 1.5832 - val_loss: 12.8634 - val_mae: 2.5892\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5762 - mae: 1.5722 - val_loss: 12.9646 - val_mae: 2.6103\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6010 - mae: 1.5825 - val_loss: 12.9659 - val_mae: 2.6091\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6016 - mae: 1.5725 - val_loss: 12.8379 - val_mae: 2.5882\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5886 - mae: 1.5784 - val_loss: 13.1320 - val_mae: 2.6334\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5099 - mae: 1.5536 - val_loss: 12.8608 - val_mae: 2.5869\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5882 - mae: 1.5760 - val_loss: 13.2372 - val_mae: 2.6416\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5802 - mae: 1.5766 - val_loss: 13.2247 - val_mae: 2.6468\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4660 - mae: 1.5463 - val_loss: 12.8804 - val_mae: 2.5861\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5259 - mae: 1.5574 - val_loss: 12.9775 - val_mae: 2.6022\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4846 - mae: 1.5560 - val_loss: 13.0823 - val_mae: 2.6206\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5253 - mae: 1.5489 - val_loss: 12.9777 - val_mae: 2.6153\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3816 - mae: 1.5314 - val_loss: 13.1211 - val_mae: 2.6293\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3792 - mae: 1.5422 - val_loss: 13.2216 - val_mae: 2.6328\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3349 - mae: 1.5207 - val_loss: 12.9936 - val_mae: 2.6078\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4021 - mae: 1.5305 - val_loss: 13.1386 - val_mae: 2.6265\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3014 - mae: 1.5231 - val_loss: 12.9413 - val_mae: 2.5954\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2613 - mae: 1.5175 - val_loss: 13.0265 - val_mae: 2.6130\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2447 - mae: 1.5076 - val_loss: 12.9537 - val_mae: 2.6022\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2575 - mae: 1.5091 - val_loss: 13.0012 - val_mae: 2.6014\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2318 - mae: 1.4903 - val_loss: 12.8275 - val_mae: 2.5804\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1584 - mae: 1.4857 - val_loss: 12.8966 - val_mae: 2.5883\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2384 - mae: 1.5083 - val_loss: 12.8792 - val_mae: 2.5918\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1981 - mae: 1.4959 - val_loss: 12.7901 - val_mae: 2.5765\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1362 - mae: 1.4858 - val_loss: 12.7122 - val_mae: 2.5639\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1300 - mae: 1.4715 - val_loss: 12.7204 - val_mae: 2.5641\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2881 - mae: 1.5288 - val_loss: 12.9488 - val_mae: 2.5982\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1370 - mae: 1.4941 - val_loss: 13.1773 - val_mae: 2.6406\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0334 - mae: 1.4680 - val_loss: 12.9015 - val_mae: 2.5948\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0395 - mae: 1.4669 - val_loss: 12.9249 - val_mae: 2.5966\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0069 - mae: 1.4633 - val_loss: 12.9910 - val_mae: 2.6053\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9996 - mae: 1.4688 - val_loss: 12.9597 - val_mae: 2.6000\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0324 - mae: 1.4667 - val_loss: 12.8589 - val_mae: 2.5858\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1034 - mae: 1.4955 - val_loss: 12.9888 - val_mae: 2.5998\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9200 - mae: 1.4457 - val_loss: 13.0740 - val_mae: 2.6216\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0087 - mae: 1.4575 - val_loss: 12.9459 - val_mae: 2.6033\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9229 - mae: 1.4551 - val_loss: 12.9899 - val_mae: 2.6049\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9481 - mae: 1.4509 - val_loss: 12.7390 - val_mae: 2.5706\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8885 - mae: 1.4397 - val_loss: 12.9130 - val_mae: 2.5935\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8510 - mae: 1.4401 - val_loss: 12.8486 - val_mae: 2.5814\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8627 - mae: 1.4347 - val_loss: 12.9000 - val_mae: 2.5858\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8330 - mae: 1.4285 - val_loss: 12.8573 - val_mae: 2.5828\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8168 - mae: 1.4206 - val_loss: 12.8906 - val_mae: 2.5903\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8038 - mae: 1.4170 - val_loss: 12.8568 - val_mae: 2.5814\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7927 - mae: 1.4185 - val_loss: 12.9449 - val_mae: 2.5984\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7608 - mae: 1.4214 - val_loss: 12.8646 - val_mae: 2.5866\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7870 - mae: 1.4160 - val_loss: 12.9127 - val_mae: 2.5947\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7526 - mae: 1.4083 - val_loss: 12.7422 - val_mae: 2.5685\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7287 - mae: 1.3953 - val_loss: 12.8251 - val_mae: 2.5795\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7278 - mae: 1.4049 - val_loss: 12.8259 - val_mae: 2.5805\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7314 - mae: 1.4135 - val_loss: 13.0392 - val_mae: 2.6222\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7071 - mae: 1.3928 - val_loss: 12.6525 - val_mae: 2.5613\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7329 - mae: 1.4088 - val_loss: 12.9214 - val_mae: 2.5930\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7155 - mae: 1.3982 - val_loss: 12.8038 - val_mae: 2.5705\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7107 - mae: 1.4141 - val_loss: 12.8690 - val_mae: 2.5795\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6697 - mae: 1.4002 - val_loss: 12.7001 - val_mae: 2.5635\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6156 - mae: 1.3727 - val_loss: 12.8654 - val_mae: 2.5930\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6323 - mae: 1.3876 - val_loss: 12.9141 - val_mae: 2.5942\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5739 - mae: 1.3789 - val_loss: 12.8001 - val_mae: 2.5812\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5954 - mae: 1.3709 - val_loss: 12.7554 - val_mae: 2.5642\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6363 - mae: 1.4062 - val_loss: 12.9540 - val_mae: 2.5896\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5995 - mae: 1.3718 - val_loss: 12.8853 - val_mae: 2.5878\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6005 - mae: 1.3947 - val_loss: 13.0620 - val_mae: 2.6038\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6033 - mae: 1.3792 - val_loss: 12.8574 - val_mae: 2.5824\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5334 - mae: 1.3698 - val_loss: 12.9367 - val_mae: 2.5929\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4958 - mae: 1.3513 - val_loss: 12.6881 - val_mae: 2.5504\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5087 - mae: 1.3564 - val_loss: 12.9813 - val_mae: 2.5927\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.4643 - mae: 2.1933\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 501.6865 - mae: 20.5377 - val_loss: 585.3679 - val_mae: 22.2503\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 472.5642 - mae: 19.8127 - val_loss: 549.4990 - val_mae: 21.4488\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 438.4330 - mae: 18.9298 - val_loss: 505.1256 - val_mae: 20.4272\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 395.9752 - mae: 17.7944 - val_loss: 450.0077 - val_mae: 19.1053\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 345.3900 - mae: 16.3512 - val_loss: 383.4319 - val_mae: 17.3864\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 285.7296 - mae: 14.6093 - val_loss: 307.7921 - val_mae: 15.2701\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 222.3852 - mae: 12.5300 - val_loss: 230.2636 - val_mae: 12.7434\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 158.8616 - mae: 10.2695 - val_loss: 163.9079 - val_mae: 10.1113\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 111.5280 - mae: 8.1265 - val_loss: 116.0355 - val_mae: 7.7103\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 80.0220 - mae: 6.5797 - val_loss: 89.8039 - val_mae: 6.6154\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 62.0836 - mae: 5.7345 - val_loss: 75.6498 - val_mae: 6.0371\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 50.4449 - mae: 5.1667 - val_loss: 65.0003 - val_mae: 5.4622\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43.1162 - mae: 4.7390 - val_loss: 55.6354 - val_mae: 4.9440\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 36.5723 - mae: 4.3556 - val_loss: 48.8526 - val_mae: 4.5166\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 31.4206 - mae: 4.0496 - val_loss: 44.4069 - val_mae: 4.2065\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 28.1924 - mae: 3.8106 - val_loss: 40.8706 - val_mae: 3.9713\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 25.6911 - mae: 3.6474 - val_loss: 38.3387 - val_mae: 3.8097\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.1769 - mae: 3.5404 - val_loss: 36.1478 - val_mae: 3.6734\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.7091 - mae: 3.4321 - val_loss: 34.2773 - val_mae: 3.5674\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.6875 - mae: 3.3598 - val_loss: 32.8654 - val_mae: 3.4894\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.8438 - mae: 3.3013 - val_loss: 31.7151 - val_mae: 3.4253\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.1069 - mae: 3.2484 - val_loss: 30.8134 - val_mae: 3.3710\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.4620 - mae: 3.1816 - val_loss: 29.9959 - val_mae: 3.3153\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.8715 - mae: 3.1219 - val_loss: 29.3037 - val_mae: 3.2702\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.3034 - mae: 3.0806 - val_loss: 28.3614 - val_mae: 3.2219\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.7390 - mae: 3.0462 - val_loss: 27.5903 - val_mae: 3.1753\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.2610 - mae: 3.0106 - val_loss: 27.0574 - val_mae: 3.1356\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.8461 - mae: 2.9822 - val_loss: 26.2633 - val_mae: 3.0972\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.3591 - mae: 2.9429 - val_loss: 25.8492 - val_mae: 3.0606\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.9646 - mae: 2.8953 - val_loss: 25.5488 - val_mae: 3.0304\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.5194 - mae: 2.8549 - val_loss: 24.9444 - val_mae: 3.0051\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.2152 - mae: 2.8366 - val_loss: 24.4171 - val_mae: 3.0042\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8631 - mae: 2.8097 - val_loss: 24.0202 - val_mae: 2.9667\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.5855 - mae: 2.7709 - val_loss: 23.8233 - val_mae: 2.9228\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.3210 - mae: 2.7475 - val_loss: 23.4895 - val_mae: 2.9129\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.9810 - mae: 2.7154 - val_loss: 23.2620 - val_mae: 2.8997\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7337 - mae: 2.6856 - val_loss: 23.0554 - val_mae: 2.8908\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.4959 - mae: 2.6578 - val_loss: 22.8344 - val_mae: 2.8883\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.3155 - mae: 2.6351 - val_loss: 22.6683 - val_mae: 2.8682\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.0771 - mae: 2.6195 - val_loss: 22.2132 - val_mae: 2.8676\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.8836 - mae: 2.6225 - val_loss: 21.9863 - val_mae: 2.8634\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6935 - mae: 2.6104 - val_loss: 21.8623 - val_mae: 2.8359\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4556 - mae: 2.5672 - val_loss: 21.8587 - val_mae: 2.8403\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.3781 - mae: 2.5334 - val_loss: 21.7752 - val_mae: 2.8494\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.2062 - mae: 2.5408 - val_loss: 21.4402 - val_mae: 2.8368\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9793 - mae: 2.5308 - val_loss: 21.3641 - val_mae: 2.8383\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 11.8443 - mae: 2.5219 - val_loss: 21.2104 - val_mae: 2.8221\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7559 - mae: 2.5104 - val_loss: 21.0795 - val_mae: 2.8295\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5698 - mae: 2.4861 - val_loss: 20.9192 - val_mae: 2.8058\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4533 - mae: 2.4686 - val_loss: 20.8228 - val_mae: 2.8013\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.2890 - mae: 2.4593 - val_loss: 20.6998 - val_mae: 2.8089\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.1611 - mae: 2.4503 - val_loss: 20.6107 - val_mae: 2.7904\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0446 - mae: 2.4273 - val_loss: 20.5363 - val_mae: 2.7873\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.9581 - mae: 2.4077 - val_loss: 20.4285 - val_mae: 2.7905\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8728 - mae: 2.3996 - val_loss: 20.3702 - val_mae: 2.7873\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7109 - mae: 2.3770 - val_loss: 20.2490 - val_mae: 2.7600\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6353 - mae: 2.3662 - val_loss: 20.1793 - val_mae: 2.7617\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5144 - mae: 2.3689 - val_loss: 20.1139 - val_mae: 2.7584\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4523 - mae: 2.3680 - val_loss: 20.0531 - val_mae: 2.7665\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3666 - mae: 2.3520 - val_loss: 20.0658 - val_mae: 2.7677\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.2902 - mae: 2.3362 - val_loss: 19.9488 - val_mae: 2.7640\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.2130 - mae: 2.3270 - val_loss: 19.9139 - val_mae: 2.7639\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1093 - mae: 2.3085 - val_loss: 19.8843 - val_mae: 2.7441\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0633 - mae: 2.3020 - val_loss: 19.8035 - val_mae: 2.7509\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0090 - mae: 2.3177 - val_loss: 19.7441 - val_mae: 2.7354\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8741 - mae: 2.2917 - val_loss: 19.7687 - val_mae: 2.7335\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8320 - mae: 2.2661 - val_loss: 19.7722 - val_mae: 2.7411\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8233 - mae: 2.2479 - val_loss: 19.7302 - val_mae: 2.7095\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7478 - mae: 2.2568 - val_loss: 19.6489 - val_mae: 2.7295\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6485 - mae: 2.2488 - val_loss: 19.6222 - val_mae: 2.7393\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6000 - mae: 2.2526 - val_loss: 19.5325 - val_mae: 2.7313\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5263 - mae: 2.2405 - val_loss: 19.4791 - val_mae: 2.7114\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4643 - mae: 2.2332 - val_loss: 19.5368 - val_mae: 2.7257\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4563 - mae: 2.2173 - val_loss: 19.5319 - val_mae: 2.7157\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3592 - mae: 2.2079 - val_loss: 19.4956 - val_mae: 2.7356\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3276 - mae: 2.1990 - val_loss: 19.4982 - val_mae: 2.7252\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2357 - mae: 2.1844 - val_loss: 19.4183 - val_mae: 2.7259\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2650 - mae: 2.1837 - val_loss: 19.3432 - val_mae: 2.6985\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.2748 - mae: 2.2093 - val_loss: 19.2772 - val_mae: 2.6947\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0396 - mae: 2.1871 - val_loss: 19.4578 - val_mae: 2.7626\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1884 - mae: 2.2064 - val_loss: 19.5293 - val_mae: 2.7893\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1148 - mae: 2.2002 - val_loss: 19.2554 - val_mae: 2.7318\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9577 - mae: 2.1714 - val_loss: 19.1870 - val_mae: 2.7106\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8893 - mae: 2.1536 - val_loss: 19.2239 - val_mae: 2.7137\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8302 - mae: 2.1369 - val_loss: 19.2149 - val_mae: 2.7088\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8369 - mae: 2.1465 - val_loss: 19.1905 - val_mae: 2.6922\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7625 - mae: 2.1191 - val_loss: 19.1946 - val_mae: 2.7040\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8567 - mae: 2.1368 - val_loss: 19.3051 - val_mae: 2.7503\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6711 - mae: 2.1217 - val_loss: 19.1548 - val_mae: 2.7017\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6257 - mae: 2.1167 - val_loss: 19.1605 - val_mae: 2.6993\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5705 - mae: 2.0954 - val_loss: 19.2038 - val_mae: 2.7230\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5794 - mae: 2.0973 - val_loss: 19.1936 - val_mae: 2.7227\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5439 - mae: 2.0977 - val_loss: 19.0995 - val_mae: 2.6967\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4847 - mae: 2.0894 - val_loss: 19.0744 - val_mae: 2.6779\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4748 - mae: 2.0768 - val_loss: 18.9691 - val_mae: 2.6603\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4861 - mae: 2.0714 - val_loss: 19.0607 - val_mae: 2.6957\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4196 - mae: 2.0786 - val_loss: 18.9566 - val_mae: 2.6830\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3482 - mae: 2.0763 - val_loss: 19.0740 - val_mae: 2.6980\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.3422 - mae: 2.0643 - val_loss: 19.1336 - val_mae: 2.7068\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2851 - mae: 2.0483 - val_loss: 19.1687 - val_mae: 2.7091\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2505 - mae: 2.0440 - val_loss: 19.0138 - val_mae: 2.6744\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3418 - mae: 2.0680 - val_loss: 19.0068 - val_mae: 2.6887\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1816 - mae: 2.0308 - val_loss: 19.0094 - val_mae: 2.6737\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2130 - mae: 2.0292 - val_loss: 18.9900 - val_mae: 2.6702\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0921 - mae: 2.0261 - val_loss: 19.0314 - val_mae: 2.6983\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0808 - mae: 2.0251 - val_loss: 19.0350 - val_mae: 2.6960\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0557 - mae: 2.0239 - val_loss: 18.9630 - val_mae: 2.6738\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9972 - mae: 2.0065 - val_loss: 18.9403 - val_mae: 2.6640\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0072 - mae: 2.0123 - val_loss: 18.8293 - val_mae: 2.6766\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9470 - mae: 1.9970 - val_loss: 18.8416 - val_mae: 2.6699\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9134 - mae: 1.9820 - val_loss: 18.7728 - val_mae: 2.6477\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.8816 - mae: 1.9920 - val_loss: 18.7619 - val_mae: 2.6449\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8804 - mae: 1.9954 - val_loss: 18.7215 - val_mae: 2.6517\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8423 - mae: 1.9924 - val_loss: 18.8298 - val_mae: 2.6858\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8348 - mae: 1.9834 - val_loss: 18.7556 - val_mae: 2.6483\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7425 - mae: 1.9687 - val_loss: 18.7787 - val_mae: 2.6587\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7113 - mae: 1.9695 - val_loss: 18.6501 - val_mae: 2.6533\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7211 - mae: 1.9823 - val_loss: 18.6683 - val_mae: 2.6365\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7058 - mae: 1.9694 - val_loss: 18.8147 - val_mae: 2.6833\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6064 - mae: 1.9528 - val_loss: 18.7198 - val_mae: 2.6399\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6189 - mae: 1.9711 - val_loss: 18.7328 - val_mae: 2.6675\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5920 - mae: 1.9673 - val_loss: 18.6033 - val_mae: 2.6586\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5763 - mae: 1.9466 - val_loss: 18.5728 - val_mae: 2.6459\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5356 - mae: 1.9410 - val_loss: 18.6113 - val_mae: 2.6539\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.4611 - mae: 1.9297 - val_loss: 18.5597 - val_mae: 2.6483\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4412 - mae: 1.9384 - val_loss: 18.6286 - val_mae: 2.6560\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4255 - mae: 1.9334 - val_loss: 18.6168 - val_mae: 2.6548\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3948 - mae: 1.9224 - val_loss: 18.5628 - val_mae: 2.6384\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4029 - mae: 1.9238 - val_loss: 18.5970 - val_mae: 2.6699\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3794 - mae: 1.9220 - val_loss: 18.4598 - val_mae: 2.6290\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3417 - mae: 1.9132 - val_loss: 18.5812 - val_mae: 2.6454\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2946 - mae: 1.9013 - val_loss: 18.5601 - val_mae: 2.6399\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2907 - mae: 1.9099 - val_loss: 18.4584 - val_mae: 2.6379\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2516 - mae: 1.9117 - val_loss: 18.4234 - val_mae: 2.6283\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1828 - mae: 1.8886 - val_loss: 18.5064 - val_mae: 2.6530\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1621 - mae: 1.8805 - val_loss: 18.5396 - val_mae: 2.6591\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.1674 - mae: 1.8925 - val_loss: 18.4803 - val_mae: 2.6301\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0884 - mae: 1.8807 - val_loss: 18.4680 - val_mae: 2.6410\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0832 - mae: 1.8781 - val_loss: 18.4315 - val_mae: 2.6273\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0995 - mae: 1.8967 - val_loss: 18.4215 - val_mae: 2.6481\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0832 - mae: 1.8806 - val_loss: 18.5081 - val_mae: 2.6540\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1128 - mae: 1.8711 - val_loss: 18.3715 - val_mae: 2.6127\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9863 - mae: 1.8556 - val_loss: 18.5127 - val_mae: 2.6558\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9704 - mae: 1.8618 - val_loss: 18.4175 - val_mae: 2.6295\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9448 - mae: 1.8544 - val_loss: 18.4237 - val_mae: 2.6376\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8941 - mae: 1.8430 - val_loss: 18.3081 - val_mae: 2.6248\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8874 - mae: 1.8278 - val_loss: 18.2917 - val_mae: 2.6146\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8755 - mae: 1.8492 - val_loss: 18.2665 - val_mae: 2.6279\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8158 - mae: 1.8546 - val_loss: 18.4118 - val_mae: 2.6789\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8059 - mae: 1.8421 - val_loss: 18.2677 - val_mae: 2.6322\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7987 - mae: 1.8390 - val_loss: 18.2135 - val_mae: 2.6100\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7438 - mae: 1.8249 - val_loss: 18.3366 - val_mae: 2.6454\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7035 - mae: 1.8062 - val_loss: 18.1697 - val_mae: 2.6290\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7111 - mae: 1.8233 - val_loss: 18.0629 - val_mae: 2.6065\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6137 - mae: 1.8089 - val_loss: 18.0942 - val_mae: 2.6232\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6240 - mae: 1.7973 - val_loss: 18.1071 - val_mae: 2.6322\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6521 - mae: 1.8032 - val_loss: 17.9793 - val_mae: 2.5984\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5603 - mae: 1.7978 - val_loss: 18.0160 - val_mae: 2.6171\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5469 - mae: 1.7951 - val_loss: 17.9911 - val_mae: 2.6257\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5035 - mae: 1.8035 - val_loss: 18.0896 - val_mae: 2.6594\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5261 - mae: 1.8013 - val_loss: 17.9704 - val_mae: 2.6149\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5876 - mae: 1.8016 - val_loss: 17.9141 - val_mae: 2.5987\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5440 - mae: 1.7890 - val_loss: 18.0810 - val_mae: 2.6670\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3882 - mae: 1.7710 - val_loss: 17.7642 - val_mae: 2.5961\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6168 - mae: 1.8218 - val_loss: 17.7281 - val_mae: 2.5750\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4368 - mae: 1.7607 - val_loss: 17.9883 - val_mae: 2.6576\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3686 - mae: 1.7656 - val_loss: 17.7664 - val_mae: 2.6160\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3471 - mae: 1.7822 - val_loss: 17.7654 - val_mae: 2.6124\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2783 - mae: 1.7559 - val_loss: 17.8615 - val_mae: 2.6353\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2778 - mae: 1.7601 - val_loss: 17.7136 - val_mae: 2.5984\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2992 - mae: 1.7370 - val_loss: 17.7395 - val_mae: 2.5914\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1780 - mae: 1.7329 - val_loss: 17.5979 - val_mae: 2.5948\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2807 - mae: 1.7784 - val_loss: 17.5910 - val_mae: 2.6021\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1215 - mae: 1.7375 - val_loss: 17.8316 - val_mae: 2.6448\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2343 - mae: 1.7210 - val_loss: 17.6318 - val_mae: 2.5944\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2005 - mae: 1.7469 - val_loss: 17.6049 - val_mae: 2.6175\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0574 - mae: 1.7262 - val_loss: 17.6543 - val_mae: 2.6166\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.1137 - mae: 1.7126 - val_loss: 17.6333 - val_mae: 2.6035\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1456 - mae: 1.7484 - val_loss: 17.6357 - val_mae: 2.6185\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0078 - mae: 1.7178 - val_loss: 17.6073 - val_mae: 2.6097\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1075 - mae: 1.7006 - val_loss: 17.4618 - val_mae: 2.5735\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9753 - mae: 1.7024 - val_loss: 17.5180 - val_mae: 2.6063\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9722 - mae: 1.7116 - val_loss: 17.4639 - val_mae: 2.5973\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9048 - mae: 1.7016 - val_loss: 17.4322 - val_mae: 2.5934\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9562 - mae: 1.6837 - val_loss: 17.4599 - val_mae: 2.5871\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8538 - mae: 1.6815 - val_loss: 17.5599 - val_mae: 2.6466\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8631 - mae: 1.7069 - val_loss: 17.4624 - val_mae: 2.6138\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8397 - mae: 1.6796 - val_loss: 17.4190 - val_mae: 2.5885\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8255 - mae: 1.6641 - val_loss: 17.3650 - val_mae: 2.5755\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8024 - mae: 1.6717 - val_loss: 17.4125 - val_mae: 2.6068\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7915 - mae: 1.6830 - val_loss: 17.3500 - val_mae: 2.6003\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7479 - mae: 1.6719 - val_loss: 17.3033 - val_mae: 2.5796\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7541 - mae: 1.6650 - val_loss: 17.4236 - val_mae: 2.6225\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7641 - mae: 1.6678 - val_loss: 17.3033 - val_mae: 2.5933\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6657 - mae: 1.6504 - val_loss: 17.3534 - val_mae: 2.6066\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6368 - mae: 1.6560 - val_loss: 17.2568 - val_mae: 2.5984\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6306 - mae: 1.6524 - val_loss: 17.3372 - val_mae: 2.6151\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6736 - mae: 1.6686 - val_loss: 17.1695 - val_mae: 2.6028\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6376 - mae: 1.6642 - val_loss: 17.3184 - val_mae: 2.6239\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5585 - mae: 1.6332 - val_loss: 17.2967 - val_mae: 2.5965\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5929 - mae: 1.6588 - val_loss: 17.1822 - val_mae: 2.6007\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6004 - mae: 1.6487 - val_loss: 17.2543 - val_mae: 2.6168\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4622 - mae: 1.6166 - val_loss: 17.0784 - val_mae: 2.5670\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5339 - mae: 1.6433 - val_loss: 16.9909 - val_mae: 2.5651\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4794 - mae: 1.6203 - val_loss: 17.1139 - val_mae: 2.6146\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4662 - mae: 1.6207 - val_loss: 16.9648 - val_mae: 2.5757\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4025 - mae: 1.6220 - val_loss: 16.9380 - val_mae: 2.5899\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3730 - mae: 1.6096 - val_loss: 16.9743 - val_mae: 2.5896\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3820 - mae: 1.5989 - val_loss: 17.0131 - val_mae: 2.6197\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3185 - mae: 1.5936 - val_loss: 16.8837 - val_mae: 2.5750\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3921 - mae: 1.6047 - val_loss: 16.8677 - val_mae: 2.5900\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3862 - mae: 1.5867 - val_loss: 16.9555 - val_mae: 2.6013\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3556 - mae: 1.6039 - val_loss: 16.8643 - val_mae: 2.5850\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3594 - mae: 1.6276 - val_loss: 17.1203 - val_mae: 2.6559\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3047 - mae: 1.5988 - val_loss: 16.8067 - val_mae: 2.5920\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2198 - mae: 1.5784 - val_loss: 16.7764 - val_mae: 2.5884\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2370 - mae: 1.5913 - val_loss: 16.8560 - val_mae: 2.6106\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1590 - mae: 1.5662 - val_loss: 16.8471 - val_mae: 2.6002\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1497 - mae: 1.5602 - val_loss: 16.7410 - val_mae: 2.5947\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1084 - mae: 1.5610 - val_loss: 16.7810 - val_mae: 2.6008\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0902 - mae: 1.5675 - val_loss: 16.7354 - val_mae: 2.6022\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1247 - mae: 1.5591 - val_loss: 16.8631 - val_mae: 2.6278\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0395 - mae: 1.5423 - val_loss: 16.7884 - val_mae: 2.5947\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0631 - mae: 1.5386 - val_loss: 16.7448 - val_mae: 2.5984\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0427 - mae: 1.5417 - val_loss: 16.6809 - val_mae: 2.6133\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0242 - mae: 1.5682 - val_loss: 16.6416 - val_mae: 2.5981\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9970 - mae: 1.5442 - val_loss: 16.5734 - val_mae: 2.5867\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0387 - mae: 1.5470 - val_loss: 16.8012 - val_mae: 2.6461\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0032 - mae: 1.5443 - val_loss: 16.6844 - val_mae: 2.6072\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9384 - mae: 1.5445 - val_loss: 16.6510 - val_mae: 2.6152\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8890 - mae: 1.5357 - val_loss: 16.4636 - val_mae: 2.6090\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8844 - mae: 1.5135 - val_loss: 16.4342 - val_mae: 2.6008\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9403 - mae: 1.5495 - val_loss: 16.3347 - val_mae: 2.5732\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9261 - mae: 1.5375 - val_loss: 16.6729 - val_mae: 2.6375\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8262 - mae: 1.5172 - val_loss: 16.3053 - val_mae: 2.5816\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8235 - mae: 1.4885 - val_loss: 16.3001 - val_mae: 2.5826\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7717 - mae: 1.5258 - val_loss: 16.4036 - val_mae: 2.6118\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8799 - mae: 1.5714 - val_loss: 16.3824 - val_mae: 2.6180\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6911 - mae: 1.5068 - val_loss: 16.2617 - val_mae: 2.5773\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7888 - mae: 1.4898 - val_loss: 16.2575 - val_mae: 2.5756\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7931 - mae: 1.5262 - val_loss: 16.3542 - val_mae: 2.6115\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6361 - mae: 1.4882 - val_loss: 16.2393 - val_mae: 2.5875\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7019 - mae: 1.4602 - val_loss: 16.2269 - val_mae: 2.5904\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7485 - mae: 1.5233 - val_loss: 16.3617 - val_mae: 2.6139\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7347 - mae: 1.4837 - val_loss: 16.1610 - val_mae: 2.5733\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5973 - mae: 1.4549 - val_loss: 16.2576 - val_mae: 2.6041\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5891 - mae: 1.4718 - val_loss: 16.2909 - val_mae: 2.5966\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5471 - mae: 1.4692 - val_loss: 16.1962 - val_mae: 2.6002\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6113 - mae: 1.5125 - val_loss: 16.1355 - val_mae: 2.6053\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5413 - mae: 1.4574 - val_loss: 16.2625 - val_mae: 2.6113\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6351 - mae: 1.4553 - val_loss: 16.0994 - val_mae: 2.5768\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6072 - mae: 1.4712 - val_loss: 16.1933 - val_mae: 2.6084\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4831 - mae: 1.4521 - val_loss: 15.9340 - val_mae: 2.5762\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5588 - mae: 1.4447 - val_loss: 15.9869 - val_mae: 2.5785\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4224 - mae: 1.4321 - val_loss: 16.0423 - val_mae: 2.5895\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4754 - mae: 1.4730 - val_loss: 15.9707 - val_mae: 2.5990\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4617 - mae: 1.4437 - val_loss: 15.9522 - val_mae: 2.5868\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5064 - mae: 1.4745 - val_loss: 16.0719 - val_mae: 2.6040\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6042 - mae: 1.4483 - val_loss: 15.9063 - val_mae: 2.5610\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4098 - mae: 1.4318 - val_loss: 16.2902 - val_mae: 2.6270\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3528 - mae: 1.4438 - val_loss: 15.9839 - val_mae: 2.5982\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3898 - mae: 1.3998 - val_loss: 15.8382 - val_mae: 2.5749\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2757 - mae: 1.4309 - val_loss: 15.9874 - val_mae: 2.6040\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2813 - mae: 1.4163 - val_loss: 15.8724 - val_mae: 2.5922\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2551 - mae: 1.4093 - val_loss: 15.8134 - val_mae: 2.5917\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4394 - mae: 1.4365 - val_loss: 15.6860 - val_mae: 2.5728\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2655 - mae: 1.4008 - val_loss: 15.9439 - val_mae: 2.6159\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1765 - mae: 1.3965 - val_loss: 15.7284 - val_mae: 2.5781\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2084 - mae: 1.4058 - val_loss: 15.6943 - val_mae: 2.5819\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1966 - mae: 1.4042 - val_loss: 15.7620 - val_mae: 2.6048\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2096 - mae: 1.3948 - val_loss: 15.6295 - val_mae: 2.5706\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1691 - mae: 1.3881 - val_loss: 15.7304 - val_mae: 2.5931\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1084 - mae: 1.3980 - val_loss: 15.7002 - val_mae: 2.5969\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0816 - mae: 1.3968 - val_loss: 15.5860 - val_mae: 2.5900\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0743 - mae: 1.3707 - val_loss: 15.5986 - val_mae: 2.5832\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0980 - mae: 1.3977 - val_loss: 15.5921 - val_mae: 2.5742\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0427 - mae: 1.3769 - val_loss: 15.7108 - val_mae: 2.6091\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0695 - mae: 1.3700 - val_loss: 15.6079 - val_mae: 2.6041\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0469 - mae: 1.3795 - val_loss: 15.5829 - val_mae: 2.5964\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0553 - mae: 1.3626 - val_loss: 15.5625 - val_mae: 2.5896\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9763 - mae: 1.3729 - val_loss: 15.7308 - val_mae: 2.6154\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0433 - mae: 1.4147 - val_loss: 15.5661 - val_mae: 2.5920\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0633 - mae: 1.3540 - val_loss: 15.3980 - val_mae: 2.5806\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0173 - mae: 1.3927 - val_loss: 15.5650 - val_mae: 2.6007\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9954 - mae: 1.3575 - val_loss: 15.5342 - val_mae: 2.6059\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9419 - mae: 1.3635 - val_loss: 15.3229 - val_mae: 2.5777\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9178 - mae: 1.3398 - val_loss: 15.5059 - val_mae: 2.6054\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8665 - mae: 1.3320 - val_loss: 15.5422 - val_mae: 2.6064\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8553 - mae: 1.3502 - val_loss: 15.3783 - val_mae: 2.5870\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9167 - mae: 1.3142 - val_loss: 15.3033 - val_mae: 2.5887\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7909 - mae: 1.3420 - val_loss: 15.4026 - val_mae: 2.6140\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8286 - mae: 1.3289 - val_loss: 15.3668 - val_mae: 2.6054\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7458 - mae: 1.3304 - val_loss: 15.6203 - val_mae: 2.6266\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7922 - mae: 1.3460 - val_loss: 15.5976 - val_mae: 2.6140\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7512 - mae: 1.3400 - val_loss: 15.3849 - val_mae: 2.5982\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7808 - mae: 1.3435 - val_loss: 15.3320 - val_mae: 2.5921\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7487 - mae: 1.3349 - val_loss: 15.3041 - val_mae: 2.6110\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6967 - mae: 1.3024 - val_loss: 15.2187 - val_mae: 2.5836\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7348 - mae: 1.2947 - val_loss: 15.1267 - val_mae: 2.5785\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8270 - mae: 1.3518 - val_loss: 15.4251 - val_mae: 2.6311\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 7.8392 - mae: 1.9862\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 609.3345 - mae: 22.8056 - val_loss: 497.9068 - val_mae: 20.5078\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 577.8969 - mae: 22.1539 - val_loss: 471.8591 - val_mae: 19.8945\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 548.0313 - mae: 21.5083 - val_loss: 444.1392 - val_mae: 19.1923\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 514.5140 - mae: 20.7456 - val_loss: 411.4177 - val_mae: 18.3241\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 475.4221 - mae: 19.8193 - val_loss: 373.2214 - val_mae: 17.2609\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 428.5772 - mae: 18.6374 - val_loss: 328.3069 - val_mae: 15.9659\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 373.8989 - mae: 17.1791 - val_loss: 276.5444 - val_mae: 14.3696\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 309.4445 - mae: 15.3449 - val_loss: 223.1098 - val_mae: 12.6493\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 245.5198 - mae: 13.2651 - val_loss: 173.1563 - val_mae: 10.8401\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 187.9840 - mae: 11.2240 - val_loss: 132.9291 - val_mae: 9.3301\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 140.5177 - mae: 9.3653 - val_loss: 105.0317 - val_mae: 8.2712\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 108.8275 - mae: 8.0008 - val_loss: 87.2583 - val_mae: 7.4431\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 86.5245 - mae: 6.9968 - val_loss: 75.7228 - val_mae: 6.8180\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 72.5408 - mae: 6.3295 - val_loss: 65.8408 - val_mae: 6.3031\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 61.7708 - mae: 5.7455 - val_loss: 56.8026 - val_mae: 5.8029\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 52.2655 - mae: 5.2002 - val_loss: 48.3387 - val_mae: 5.3130\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 44.8177 - mae: 4.7700 - val_loss: 41.6767 - val_mae: 4.8863\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 39.0162 - mae: 4.4127 - val_loss: 36.8507 - val_mae: 4.5875\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 34.5070 - mae: 4.1595 - val_loss: 33.0512 - val_mae: 4.3388\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 31.3828 - mae: 3.9594 - val_loss: 30.2051 - val_mae: 4.1302\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 28.8195 - mae: 3.7890 - val_loss: 27.9200 - val_mae: 3.9638\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 27.0802 - mae: 3.6694 - val_loss: 26.4006 - val_mae: 3.8547\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25.7124 - mae: 3.5760 - val_loss: 25.0051 - val_mae: 3.7483\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.4657 - mae: 3.4816 - val_loss: 23.9079 - val_mae: 3.6531\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 23.5872 - mae: 3.4099 - val_loss: 22.8886 - val_mae: 3.5602\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.9123 - mae: 3.3575 - val_loss: 22.2572 - val_mae: 3.5066\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 22.1046 - mae: 3.3043 - val_loss: 21.7867 - val_mae: 3.4679\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.5257 - mae: 3.2711 - val_loss: 21.8869 - val_mae: 3.4964\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.0109 - mae: 3.2478 - val_loss: 21.5559 - val_mae: 3.4494\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.4327 - mae: 3.1970 - val_loss: 20.7923 - val_mae: 3.3663\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.9964 - mae: 3.1360 - val_loss: 20.3232 - val_mae: 3.3197\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.5832 - mae: 3.1023 - val_loss: 19.9437 - val_mae: 3.2715\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.2158 - mae: 3.0603 - val_loss: 19.3379 - val_mae: 3.2083\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.8786 - mae: 3.0211 - val_loss: 19.1726 - val_mae: 3.1787\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 18.5560 - mae: 3.0102 - val_loss: 19.0697 - val_mae: 3.1604\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.2407 - mae: 2.9923 - val_loss: 18.7859 - val_mae: 3.1224\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.9974 - mae: 2.9715 - val_loss: 18.6941 - val_mae: 3.1009\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.6356 - mae: 2.9367 - val_loss: 18.3284 - val_mae: 3.0580\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.4027 - mae: 2.9015 - val_loss: 18.0428 - val_mae: 3.0260\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.1653 - mae: 2.8885 - val_loss: 18.2890 - val_mae: 3.0560\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.9081 - mae: 2.8811 - val_loss: 18.0549 - val_mae: 3.0253\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7081 - mae: 2.8596 - val_loss: 17.8778 - val_mae: 3.0132\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.4837 - mae: 2.8305 - val_loss: 17.7874 - val_mae: 3.0014\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.3530 - mae: 2.8375 - val_loss: 18.2057 - val_mae: 3.0462\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.1001 - mae: 2.8276 - val_loss: 17.7029 - val_mae: 2.9952\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.8633 - mae: 2.7819 - val_loss: 17.2750 - val_mae: 2.9639\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.7345 - mae: 2.7445 - val_loss: 17.1118 - val_mae: 2.9369\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.5813 - mae: 2.7308 - val_loss: 17.2108 - val_mae: 2.9487\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.3650 - mae: 2.7264 - val_loss: 17.1742 - val_mae: 2.9420\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 15.2201 - mae: 2.7126 - val_loss: 16.9707 - val_mae: 2.9345\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 15.0356 - mae: 2.7083 - val_loss: 17.1806 - val_mae: 2.9626\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.9883 - mae: 2.7341 - val_loss: 17.1928 - val_mae: 2.9714\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.8561 - mae: 2.6964 - val_loss: 16.4774 - val_mae: 2.9134\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.6482 - mae: 2.6685 - val_loss: 16.6222 - val_mae: 2.9187\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.4539 - mae: 2.6635 - val_loss: 16.5926 - val_mae: 2.9241\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.3712 - mae: 2.6549 - val_loss: 16.3675 - val_mae: 2.9000\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.1980 - mae: 2.6344 - val_loss: 16.2771 - val_mae: 2.9063\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.1227 - mae: 2.6343 - val_loss: 16.2713 - val_mae: 2.9082\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.0334 - mae: 2.6371 - val_loss: 16.3768 - val_mae: 2.9233\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.8183 - mae: 2.6019 - val_loss: 15.9161 - val_mae: 2.8740\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7346 - mae: 2.5836 - val_loss: 15.9907 - val_mae: 2.8809\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.5971 - mae: 2.5809 - val_loss: 16.0205 - val_mae: 2.9026\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.5112 - mae: 2.5854 - val_loss: 16.0019 - val_mae: 2.8982\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.4023 - mae: 2.5607 - val_loss: 15.6523 - val_mae: 2.8630\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.2970 - mae: 2.5503 - val_loss: 15.6686 - val_mae: 2.8601\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.2049 - mae: 2.5423 - val_loss: 15.6445 - val_mae: 2.8640\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.0904 - mae: 2.5424 - val_loss: 15.7798 - val_mae: 2.8835\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.9523 - mae: 2.5325 - val_loss: 15.6259 - val_mae: 2.8696\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.8760 - mae: 2.5144 - val_loss: 15.3342 - val_mae: 2.8449\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.7881 - mae: 2.5078 - val_loss: 15.2992 - val_mae: 2.8433\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6820 - mae: 2.5107 - val_loss: 15.3713 - val_mae: 2.8582\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6091 - mae: 2.5134 - val_loss: 15.3995 - val_mae: 2.8694\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.4957 - mae: 2.4958 - val_loss: 15.0336 - val_mae: 2.8387\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.5243 - mae: 2.4761 - val_loss: 14.8891 - val_mae: 2.8068\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.3330 - mae: 2.4756 - val_loss: 15.3493 - val_mae: 2.8599\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.3167 - mae: 2.5008 - val_loss: 15.2063 - val_mae: 2.8508\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.2171 - mae: 2.4674 - val_loss: 14.8583 - val_mae: 2.8380\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.0879 - mae: 2.4406 - val_loss: 14.7288 - val_mae: 2.8017\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.1228 - mae: 2.4591 - val_loss: 14.9413 - val_mae: 2.7944\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.0480 - mae: 2.4662 - val_loss: 14.8162 - val_mae: 2.8161\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.8665 - mae: 2.4398 - val_loss: 14.7310 - val_mae: 2.8312\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.8074 - mae: 2.4319 - val_loss: 14.4171 - val_mae: 2.7824\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.7979 - mae: 2.4115 - val_loss: 14.2867 - val_mae: 2.7811\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5977 - mae: 2.4117 - val_loss: 14.5973 - val_mae: 2.8024\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5429 - mae: 2.4264 - val_loss: 14.5547 - val_mae: 2.8075\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4776 - mae: 2.4178 - val_loss: 14.4330 - val_mae: 2.8105\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.4514 - mae: 2.4096 - val_loss: 14.4659 - val_mae: 2.8087\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.4876 - mae: 2.3985 - val_loss: 13.9707 - val_mae: 2.7574\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.2051 - mae: 2.3763 - val_loss: 14.3448 - val_mae: 2.7814\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3308 - mae: 2.4307 - val_loss: 14.8400 - val_mae: 2.8293\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1385 - mae: 2.4111 - val_loss: 14.2507 - val_mae: 2.7818\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.1626 - mae: 2.3622 - val_loss: 13.8567 - val_mae: 2.7720\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0122 - mae: 2.3474 - val_loss: 13.7229 - val_mae: 2.7399\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.9176 - mae: 2.3477 - val_loss: 13.9564 - val_mae: 2.7644\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8554 - mae: 2.3695 - val_loss: 14.2574 - val_mae: 2.8037\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.8694 - mae: 2.3764 - val_loss: 14.1275 - val_mae: 2.7838\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.7011 - mae: 2.3322 - val_loss: 13.6373 - val_mae: 2.7409\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7180 - mae: 2.3180 - val_loss: 13.4884 - val_mae: 2.7141\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6389 - mae: 2.3276 - val_loss: 13.7850 - val_mae: 2.7575\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.7576 - mae: 2.3717 - val_loss: 14.2149 - val_mae: 2.7941\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4274 - mae: 2.3224 - val_loss: 13.5846 - val_mae: 2.7383\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.5268 - mae: 2.2952 - val_loss: 13.2502 - val_mae: 2.6993\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.3767 - mae: 2.3038 - val_loss: 13.5003 - val_mae: 2.7150\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.3715 - mae: 2.3074 - val_loss: 13.5255 - val_mae: 2.7464\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.3583 - mae: 2.3119 - val_loss: 13.7187 - val_mae: 2.7517\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.1576 - mae: 2.2826 - val_loss: 13.2359 - val_mae: 2.6855\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.1277 - mae: 2.2722 - val_loss: 13.2219 - val_mae: 2.6876\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.0705 - mae: 2.2710 - val_loss: 13.2397 - val_mae: 2.7120\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9818 - mae: 2.2642 - val_loss: 13.3330 - val_mae: 2.7148\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9660 - mae: 2.2600 - val_loss: 13.2859 - val_mae: 2.7041\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8754 - mae: 2.2735 - val_loss: 13.8640 - val_mae: 2.7589\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.8559 - mae: 2.2812 - val_loss: 13.3285 - val_mae: 2.7135\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7548 - mae: 2.2528 - val_loss: 13.2025 - val_mae: 2.7076\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.8089 - mae: 2.2345 - val_loss: 12.9122 - val_mae: 2.6835\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6888 - mae: 2.2274 - val_loss: 13.0061 - val_mae: 2.6767\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6376 - mae: 2.2395 - val_loss: 13.2264 - val_mae: 2.6999\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5385 - mae: 2.2237 - val_loss: 12.9773 - val_mae: 2.7014\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5500 - mae: 2.2300 - val_loss: 13.1532 - val_mae: 2.6935\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4201 - mae: 2.2210 - val_loss: 13.0724 - val_mae: 2.6985\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3612 - mae: 2.2114 - val_loss: 12.8885 - val_mae: 2.6923\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.3257 - mae: 2.2031 - val_loss: 12.8232 - val_mae: 2.6692\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.3516 - mae: 2.1938 - val_loss: 12.6596 - val_mae: 2.6583\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2673 - mae: 2.1933 - val_loss: 13.0788 - val_mae: 2.6739\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1972 - mae: 2.1967 - val_loss: 13.0896 - val_mae: 2.6990\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1345 - mae: 2.1860 - val_loss: 12.8504 - val_mae: 2.6668\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1599 - mae: 2.1825 - val_loss: 12.9125 - val_mae: 2.6730\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.1094 - mae: 2.1705 - val_loss: 12.5196 - val_mae: 2.6659\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4808 - mae: 2.2362 - val_loss: 13.5329 - val_mae: 2.7415\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0723 - mae: 2.1826 - val_loss: 12.4315 - val_mae: 2.6504\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.0233 - mae: 2.1601 - val_loss: 12.8222 - val_mae: 2.6670\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8504 - mae: 2.1504 - val_loss: 12.8325 - val_mae: 2.6960\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8365 - mae: 2.1778 - val_loss: 13.3085 - val_mae: 2.6914\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.7805 - mae: 2.1678 - val_loss: 12.8137 - val_mae: 2.6706\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.7094 - mae: 2.1340 - val_loss: 12.5436 - val_mae: 2.6628\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.8026 - mae: 2.1448 - val_loss: 12.7532 - val_mae: 2.6399\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.5405 - mae: 2.1290 - val_loss: 12.6913 - val_mae: 2.6895\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6732 - mae: 2.1310 - val_loss: 12.3190 - val_mae: 2.6552\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6011 - mae: 2.1213 - val_loss: 12.7813 - val_mae: 2.6657\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4577 - mae: 2.1164 - val_loss: 12.4825 - val_mae: 2.6249\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.4009 - mae: 2.1099 - val_loss: 12.5431 - val_mae: 2.6409\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3283 - mae: 2.0987 - val_loss: 12.3534 - val_mae: 2.6358\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2838 - mae: 2.0939 - val_loss: 12.2417 - val_mae: 2.6177\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2503 - mae: 2.0920 - val_loss: 12.1774 - val_mae: 2.6109\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2145 - mae: 2.0922 - val_loss: 12.3558 - val_mae: 2.6254\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1625 - mae: 2.0806 - val_loss: 12.1845 - val_mae: 2.6111\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1450 - mae: 2.0825 - val_loss: 12.4855 - val_mae: 2.6368\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0481 - mae: 2.0753 - val_loss: 12.0518 - val_mae: 2.6127\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0397 - mae: 2.0577 - val_loss: 12.0053 - val_mae: 2.5973\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0076 - mae: 2.0678 - val_loss: 12.4028 - val_mae: 2.6218\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9736 - mae: 2.0742 - val_loss: 12.1680 - val_mae: 2.6186\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9395 - mae: 2.0512 - val_loss: 11.9347 - val_mae: 2.5847\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8752 - mae: 2.0533 - val_loss: 12.5746 - val_mae: 2.6305\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8881 - mae: 2.0671 - val_loss: 12.0575 - val_mae: 2.5934\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7556 - mae: 2.0399 - val_loss: 12.0220 - val_mae: 2.6079\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7935 - mae: 2.0409 - val_loss: 12.1030 - val_mae: 2.6074\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7867 - mae: 2.0284 - val_loss: 11.7873 - val_mae: 2.5736\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7275 - mae: 2.0303 - val_loss: 11.9433 - val_mae: 2.5802\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6003 - mae: 2.0229 - val_loss: 11.9452 - val_mae: 2.5933\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5901 - mae: 2.0116 - val_loss: 11.9044 - val_mae: 2.5879\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5238 - mae: 2.0040 - val_loss: 11.8941 - val_mae: 2.5876\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6521 - mae: 2.0399 - val_loss: 12.1259 - val_mae: 2.5934\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5873 - mae: 2.0071 - val_loss: 11.5722 - val_mae: 2.5591\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.5157 - mae: 2.0011 - val_loss: 11.9846 - val_mae: 2.5724\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3787 - mae: 2.0002 - val_loss: 11.6908 - val_mae: 2.5612\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3430 - mae: 1.9796 - val_loss: 11.5671 - val_mae: 2.5548\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4038 - mae: 1.9966 - val_loss: 11.7801 - val_mae: 2.5646\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3723 - mae: 1.9974 - val_loss: 11.4076 - val_mae: 2.5162\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3405 - mae: 1.9935 - val_loss: 11.7152 - val_mae: 2.5558\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.2426 - mae: 1.9769 - val_loss: 11.6664 - val_mae: 2.5527\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2096 - mae: 1.9691 - val_loss: 11.6370 - val_mae: 2.5339\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1499 - mae: 1.9716 - val_loss: 11.5585 - val_mae: 2.5285\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1499 - mae: 1.9609 - val_loss: 11.5419 - val_mae: 2.5335\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1574 - mae: 1.9598 - val_loss: 11.3234 - val_mae: 2.5184\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0162 - mae: 1.9439 - val_loss: 11.4336 - val_mae: 2.5204\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9805 - mae: 1.9409 - val_loss: 11.4703 - val_mae: 2.5106\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9896 - mae: 1.9456 - val_loss: 11.5546 - val_mae: 2.5240\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9716 - mae: 1.9317 - val_loss: 11.4808 - val_mae: 2.5095\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9354 - mae: 1.9371 - val_loss: 11.6362 - val_mae: 2.5181\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9401 - mae: 1.9460 - val_loss: 11.6174 - val_mae: 2.5312\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8418 - mae: 1.9265 - val_loss: 11.1189 - val_mae: 2.4743\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8142 - mae: 1.9129 - val_loss: 11.3749 - val_mae: 2.5009\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7625 - mae: 1.9147 - val_loss: 11.2752 - val_mae: 2.4875\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7662 - mae: 1.9120 - val_loss: 11.1416 - val_mae: 2.4923\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8348 - mae: 1.9365 - val_loss: 10.9120 - val_mae: 2.4246\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7500 - mae: 1.9105 - val_loss: 11.1913 - val_mae: 2.4872\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6994 - mae: 1.8841 - val_loss: 11.0554 - val_mae: 2.4706\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5382 - mae: 1.8787 - val_loss: 11.3340 - val_mae: 2.4775\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7771 - mae: 1.9249 - val_loss: 11.3776 - val_mae: 2.4795\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5346 - mae: 1.8828 - val_loss: 11.1892 - val_mae: 2.4626\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5413 - mae: 1.8842 - val_loss: 11.1741 - val_mae: 2.4735\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3965 - mae: 1.8665 - val_loss: 10.9921 - val_mae: 2.4356\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3790 - mae: 1.8554 - val_loss: 11.0446 - val_mae: 2.4455\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3543 - mae: 1.8587 - val_loss: 11.2720 - val_mae: 2.4776\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2822 - mae: 1.8483 - val_loss: 10.9980 - val_mae: 2.4503\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2910 - mae: 1.8491 - val_loss: 11.0588 - val_mae: 2.4354\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1929 - mae: 1.8357 - val_loss: 10.8628 - val_mae: 2.4476\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2339 - mae: 1.8347 - val_loss: 11.1013 - val_mae: 2.4751\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.2000 - mae: 1.8465 - val_loss: 11.0484 - val_mae: 2.4436\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1182 - mae: 1.8312 - val_loss: 10.8935 - val_mae: 2.4388\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.1773 - mae: 1.8178 - val_loss: 10.8433 - val_mae: 2.4354\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2305 - mae: 1.8480 - val_loss: 11.5253 - val_mae: 2.4776\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0437 - mae: 1.8050 - val_loss: 10.7837 - val_mae: 2.4357\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.0813 - mae: 1.8019 - val_loss: 10.6863 - val_mae: 2.4031\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0921 - mae: 1.8172 - val_loss: 11.2350 - val_mae: 2.4389\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8899 - mae: 1.7906 - val_loss: 10.8137 - val_mae: 2.4260\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.9724 - mae: 1.7828 - val_loss: 10.7352 - val_mae: 2.4269\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.9740 - mae: 1.7977 - val_loss: 11.0577 - val_mae: 2.4376\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8563 - mae: 1.7786 - val_loss: 10.6368 - val_mae: 2.3932\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.8447 - mae: 1.7654 - val_loss: 10.8129 - val_mae: 2.4229\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8200 - mae: 1.7812 - val_loss: 10.8170 - val_mae: 2.4204\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7639 - mae: 1.7666 - val_loss: 10.6473 - val_mae: 2.4014\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8018 - mae: 1.7540 - val_loss: 10.6073 - val_mae: 2.3943\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7740 - mae: 1.7746 - val_loss: 11.1081 - val_mae: 2.4390\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7077 - mae: 1.7761 - val_loss: 10.3125 - val_mae: 2.3522\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7415 - mae: 1.7404 - val_loss: 10.6390 - val_mae: 2.4030\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5978 - mae: 1.7401 - val_loss: 11.0517 - val_mae: 2.4282\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5962 - mae: 1.7505 - val_loss: 10.6435 - val_mae: 2.3892\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5640 - mae: 1.7320 - val_loss: 10.5800 - val_mae: 2.3921\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5562 - mae: 1.7341 - val_loss: 10.7768 - val_mae: 2.4034\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4986 - mae: 1.7275 - val_loss: 10.2930 - val_mae: 2.3437\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6615 - mae: 1.7490 - val_loss: 10.7155 - val_mae: 2.4177\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6243 - mae: 1.7405 - val_loss: 10.2420 - val_mae: 2.3466\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.6095 - mae: 1.7437 - val_loss: 10.9254 - val_mae: 2.4049\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4418 - mae: 1.7095 - val_loss: 10.3966 - val_mae: 2.3705\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4240 - mae: 1.6907 - val_loss: 10.3873 - val_mae: 2.3591\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3298 - mae: 1.6965 - val_loss: 10.7780 - val_mae: 2.4109\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3613 - mae: 1.7050 - val_loss: 10.5068 - val_mae: 2.3654\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3363 - mae: 1.7169 - val_loss: 10.9652 - val_mae: 2.4101\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3491 - mae: 1.7271 - val_loss: 10.9015 - val_mae: 2.4093\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2993 - mae: 1.7038 - val_loss: 10.4506 - val_mae: 2.3580\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2698 - mae: 1.7131 - val_loss: 10.9949 - val_mae: 2.4201\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2406 - mae: 1.6977 - val_loss: 10.4564 - val_mae: 2.3544\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1780 - mae: 1.6858 - val_loss: 10.9764 - val_mae: 2.4219\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1693 - mae: 1.6868 - val_loss: 10.6072 - val_mae: 2.3829\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.1603 - mae: 1.6811 - val_loss: 10.5637 - val_mae: 2.3713\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0797 - mae: 1.6697 - val_loss: 10.9150 - val_mae: 2.4197\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1185 - mae: 1.6898 - val_loss: 11.0236 - val_mae: 2.4146\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1184 - mae: 1.6789 - val_loss: 10.6742 - val_mae: 2.3718\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0919 - mae: 1.6883 - val_loss: 11.0780 - val_mae: 2.4261\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9899 - mae: 1.6680 - val_loss: 10.5553 - val_mae: 2.3817\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0622 - mae: 1.6622 - val_loss: 10.6405 - val_mae: 2.3799\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9737 - mae: 1.6620 - val_loss: 10.7597 - val_mae: 2.4012\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9457 - mae: 1.6534 - val_loss: 10.5097 - val_mae: 2.3845\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9448 - mae: 1.6540 - val_loss: 10.6079 - val_mae: 2.3697\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0256 - mae: 1.6588 - val_loss: 10.4177 - val_mae: 2.3674\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9359 - mae: 1.6653 - val_loss: 10.7325 - val_mae: 2.4011\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8923 - mae: 1.6264 - val_loss: 10.3727 - val_mae: 2.3421\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0596 - mae: 1.6779 - val_loss: 11.0183 - val_mae: 2.4135\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.8358 - mae: 1.6487 - val_loss: 10.4297 - val_mae: 2.3639\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8896 - mae: 1.6445 - val_loss: 10.5139 - val_mae: 2.3613\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8748 - mae: 1.6407 - val_loss: 10.4980 - val_mae: 2.3968\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8574 - mae: 1.6476 - val_loss: 10.7227 - val_mae: 2.3796\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.7449 - mae: 1.6284 - val_loss: 10.4787 - val_mae: 2.3826\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 4.7357 - mae: 1.6250 - val_loss: 10.4535 - val_mae: 2.3641\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7960 - mae: 1.6397 - val_loss: 10.6258 - val_mae: 2.3774\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.7223 - mae: 1.6010 - val_loss: 10.3722 - val_mae: 2.3621\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6694 - mae: 1.6148 - val_loss: 10.6154 - val_mae: 2.3832\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6897 - mae: 1.6395 - val_loss: 10.4579 - val_mae: 2.3764\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6363 - mae: 1.6065 - val_loss: 10.5300 - val_mae: 2.3747\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6115 - mae: 1.6189 - val_loss: 10.6873 - val_mae: 2.3922\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6168 - mae: 1.6274 - val_loss: 10.3222 - val_mae: 2.3537\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6247 - mae: 1.6109 - val_loss: 10.4439 - val_mae: 2.3512\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6897 - mae: 1.6391 - val_loss: 10.6147 - val_mae: 2.4009\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5146 - mae: 1.5937 - val_loss: 10.1703 - val_mae: 2.3325\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6314 - mae: 1.5794 - val_loss: 10.2830 - val_mae: 2.3469\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5128 - mae: 1.5973 - val_loss: 10.5969 - val_mae: 2.3944\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5014 - mae: 1.5996 - val_loss: 10.4001 - val_mae: 2.3577\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4811 - mae: 1.5871 - val_loss: 10.5136 - val_mae: 2.3577\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4585 - mae: 1.5869 - val_loss: 10.3276 - val_mae: 2.3551\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4737 - mae: 1.5698 - val_loss: 10.3923 - val_mae: 2.3625\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5337 - mae: 1.6282 - val_loss: 10.3885 - val_mae: 2.3660\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4199 - mae: 1.5881 - val_loss: 10.3066 - val_mae: 2.3710\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4212 - mae: 1.5682 - val_loss: 10.3841 - val_mae: 2.3370\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4232 - mae: 1.5722 - val_loss: 10.2945 - val_mae: 2.3463\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3764 - mae: 1.5777 - val_loss: 10.4998 - val_mae: 2.3779\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3962 - mae: 1.5873 - val_loss: 10.0804 - val_mae: 2.3189\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3848 - mae: 1.5439 - val_loss: 10.0586 - val_mae: 2.3247\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4916 - mae: 1.6182 - val_loss: 10.7078 - val_mae: 2.4297\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4060 - mae: 1.5729 - val_loss: 10.1075 - val_mae: 2.3194\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2795 - mae: 1.5540 - val_loss: 10.3877 - val_mae: 2.3783\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3420 - mae: 1.5716 - val_loss: 10.4058 - val_mae: 2.3686\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3325 - mae: 1.5843 - val_loss: 10.2029 - val_mae: 2.3446\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2822 - mae: 1.5429 - val_loss: 10.2600 - val_mae: 2.3540\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2707 - mae: 1.5462 - val_loss: 10.5158 - val_mae: 2.3779\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2590 - mae: 1.5512 - val_loss: 10.2835 - val_mae: 2.3546\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2586 - mae: 1.5590 - val_loss: 10.3612 - val_mae: 2.3572\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2382 - mae: 1.5631 - val_loss: 10.5454 - val_mae: 2.3891\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2386 - mae: 1.5546 - val_loss: 10.3530 - val_mae: 2.3634\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1879 - mae: 1.5472 - val_loss: 10.4568 - val_mae: 2.3719\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1648 - mae: 1.5275 - val_loss: 10.3308 - val_mae: 2.3449\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1846 - mae: 1.5288 - val_loss: 10.2730 - val_mae: 2.3409\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1342 - mae: 1.5194 - val_loss: 10.4659 - val_mae: 2.3697\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2522 - mae: 1.5734 - val_loss: 10.5168 - val_mae: 2.3841\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1285 - mae: 1.5476 - val_loss: 10.4996 - val_mae: 2.3839\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2388 - mae: 1.5412 - val_loss: 10.1294 - val_mae: 2.3351\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2699 - mae: 1.5649 - val_loss: 10.7467 - val_mae: 2.4114\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1131 - mae: 1.5210 - val_loss: 10.0399 - val_mae: 2.3157\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1230 - mae: 1.5083 - val_loss: 10.4828 - val_mae: 2.3762\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0645 - mae: 1.5317 - val_loss: 10.3993 - val_mae: 2.3668\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0532 - mae: 1.5187 - val_loss: 10.2874 - val_mae: 2.3645\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 9.5873 - mae: 2.1939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9GfGYcXxhhr",
        "colab_type": "text"
      },
      "source": [
        "K-Fold 결과 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpFu7vDQxnjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "696b873a-ce47-4f8e-bb52-c0901f3af308"
      },
      "source": [
        "print(mae_list)\n",
        "print(np.mean(mae_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.1932740211486816, 1.9861738681793213, 2.193887233734131]\n",
            "2.1244450410207114\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}